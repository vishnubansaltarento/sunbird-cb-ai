{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15eb081c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from langchain.document_loaders import NotionDirectoryLoader\n",
    "from langchain.text_splitter import MarkdownHeaderTextSplitter, RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Milvus\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
    "from langchain.chains.query_constructor.base import AttributeInfo\n",
    "from pymilvus import connections, utility\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8594dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f612620f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install milvus_kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61fc0edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install git+git://github.com/Hourout/milvus_kernel.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16718816",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install milvus_kernel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1887d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a638e37b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c50c1d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/content/milvus/core/milvus/lib'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import os\n",
    "\n",
    "# # Define the directory you want to append to LD_LIBRARY_PATH\n",
    "# new_ld_library_path = \"/content/milvus/core/milvus/lib\"\n",
    "\n",
    "# # Check if LD_LIBRARY_PATH is already defined, and if not, set it\n",
    "# if 'LD_LIBRARY_PATH' not in os.environ:\n",
    "#     os.environ['LD_LIBRARY_PATH'] = new_ld_library_path\n",
    "# else:\n",
    "#     os.environ['LD_LIBRARY_PATH'] += \":\" + new_ld_library_path\n",
    "\n",
    "# # Verify the updated LD_LIBRARY_PATH\n",
    "# os.environ['LD_LIBRARY_PATH']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1052176",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # % cd /content/milvus/core/milvus\n",
    "# ! echo $LD_LIBRARY_PATH\n",
    "# import os\n",
    "# os.environ['LD_LIBRARY_PATH'] +=\":/content/milvus/core/milvus/lib\"\n",
    "# ! echo $LD_LIBRARY_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f55ec45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create table test01 where dimension=128 and index_file_size=1024 and metric_type='L2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94681da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import milvus \n",
    "\n",
    "# # milvus = Milvus(host='localhost', port='19530')\n",
    "\n",
    "# # Create a collection\n",
    "# collection_name = 'my_collection'\n",
    "# milvus.create_collection(collection_name, dimension=128, index_file_size=1024, metric_type=MetricType.L2)\n",
    "\n",
    "# # Insert vectors\n",
    "# vectors = [[0.1, 0.2, 0.3, ...], [0.4, 0.5, 0.6, ...], ...]\n",
    "# milvus.insert(collection_name, records=vectors)\n",
    "\n",
    "# # Search for similar vectors\n",
    "# query_vector = [0.3, 0.4, 0.5, ...]\n",
    "# results = milvus.search(collection_name, query_records=[query_vector], top_k=10)\n",
    "# print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df41c137",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "89d43876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Skipping pymilvus as it is not installed.\n"
     ]
    }
   ],
   "source": [
    "# pip uninstall pymilvus==2.3.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b2de3323",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  python setup.py bdist_wheel did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [190 lines of output]\n",
      "  C:\\Users\\Palash Ashok Bhosale\\AppData\\Local\\Temp\\pip-install-zsb3h_y3\\grpcio_d87d3504aca3458991da8152c7bf642a\\setup.py:31: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n",
      "    import pkg_resources\n",
      "  ASM Builds for BoringSSL currently not supported on: win-amd64\n",
      "  Found cython-generated files...\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  running build_project_metadata\n",
      "  creating python_build\n",
      "  creating python_build\\lib.win-amd64-cpython-311\n",
      "  creating python_build\\lib.win-amd64-cpython-311\\grpc\n",
      "  copying src\\python\\grpcio\\grpc\\_auth.py -> python_build\\lib.win-amd64-cpython-311\\grpc\n",
      "  copying src\\python\\grpcio\\grpc\\_channel.py -> python_build\\lib.win-amd64-cpython-311\\grpc\n",
      "  copying src\\python\\grpcio\\grpc\\_common.py -> python_build\\lib.win-amd64-cpython-311\\grpc\n",
      "  copying src\\python\\grpcio\\grpc\\_compression.py -> python_build\\lib.win-amd64-cpython-311\\grpc\n",
      "  copying src\\python\\grpcio\\grpc\\_grpcio_metadata.py -> python_build\\lib.win-amd64-cpython-311\\grpc\n",
      "  copying src\\python\\grpcio\\grpc\\_interceptor.py -> python_build\\lib.win-amd64-cpython-311\\grpc\n",
      "  copying src\\python\\grpcio\\grpc\\_plugin_wrapping.py -> python_build\\lib.win-amd64-cpython-311\\grpc\n",
      "  copying src\\python\\grpcio\\grpc\\_runtime_protos.py -> python_build\\lib.win-amd64-cpython-311\\grpc\n",
      "  copying src\\python\\grpcio\\grpc\\_server.py -> python_build\\lib.win-amd64-cpython-311\\grpc\n",
      "  copying src\\python\\grpcio\\grpc\\_simple_stubs.py -> python_build\\lib.win-amd64-cpython-311\\grpc\n",
      "  copying src\\python\\grpcio\\grpc\\_utilities.py -> python_build\\lib.win-amd64-cpython-311\\grpc\n",
      "  copying src\\python\\grpcio\\grpc\\__init__.py -> python_build\\lib.win-amd64-cpython-311\\grpc\n",
      "  creating python_build\\lib.win-amd64-cpython-311\\grpc\\aio\n",
      "  copying src\\python\\grpcio\\grpc\\aio\\_base_call.py -> python_build\\lib.win-amd64-cpython-311\\grpc\\aio\n",
      "  copying src\\python\\grpcio\\grpc\\aio\\_base_channel.py -> python_build\\lib.win-amd64-cpython-311\\grpc\\aio\n",
      "  copying src\\python\\grpcio\\grpc\\aio\\_base_server.py -> python_build\\lib.win-amd64-cpython-311\\grpc\\aio\n",
      "  copying src\\python\\grpcio\\grpc\\aio\\_call.py -> python_build\\lib.win-amd64-cpython-311\\grpc\\aio\n",
      "  copying src\\python\\grpcio\\grpc\\aio\\_channel.py -> python_build\\lib.win-amd64-cpython-311\\grpc\\aio\n",
      "  copying src\\python\\grpcio\\grpc\\aio\\_interceptor.py -> python_build\\lib.win-amd64-cpython-311\\grpc\\aio\n",
      "  copying src\\python\\grpcio\\grpc\\aio\\_metadata.py -> python_build\\lib.win-amd64-cpython-311\\grpc\\aio\n",
      "  copying src\\python\\grpcio\\grpc\\aio\\_server.py -> python_build\\lib.win-amd64-cpython-311\\grpc\\aio\n",
      "  copying src\\python\\grpcio\\grpc\\aio\\_typing.py -> python_build\\lib.win-amd64-cpython-311\\grpc\\aio\n",
      "  copying src\\python\\grpcio\\grpc\\aio\\_utils.py -> python_build\\lib.win-amd64-cpython-311\\grpc\\aio\n",
      "  copying src\\python\\grpcio\\grpc\\aio\\__init__.py -> python_build\\lib.win-amd64-cpython-311\\grpc\\aio\n",
      "  creating python_build\\lib.win-amd64-cpython-311\\grpc\\beta\n",
      "  copying src\\python\\grpcio\\grpc\\beta\\implementations.py -> python_build\\lib.win-amd64-cpython-311\\grpc\\beta\n",
      "  copying src\\python\\grpcio\\grpc\\beta\\interfaces.py -> python_build\\lib.win-amd64-cpython-311\\grpc\\beta\n",
      "  copying src\\python\\grpcio\\grpc\\beta\\utilities.py -> python_build\\lib.win-amd64-cpython-311\\grpc\\beta\n",
      "  copying src\\python\\grpcio\\grpc\\beta\\_client_adaptations.py -> python_build\\lib.win-amd64-cpython-311\\grpc\\beta\n",
      "  copying src\\python\\grpcio\\grpc\\beta\\_metadata.py -> python_build\\lib.win-amd64-cpython-311\\grpc\\beta\n",
      "  copying src\\python\\grpcio\\grpc\\beta\\_server_adaptations.py -> python_build\\lib.win-amd64-cpython-311\\grpc\\beta\n",
      "  copying src\\python\\grpcio\\grpc\\beta\\__init__.py -> python_build\\lib.win-amd64-cpython-311\\grpc\\beta\n",
      "  creating python_build\\lib.win-amd64-cpython-311\\grpc\\experimental\n",
      "  copying src\\python\\grpcio\\grpc\\experimental\\gevent.py -> python_build\\lib.win-amd64-cpython-311\\grpc\\experimental\n",
      "  copying src\\python\\grpcio\\grpc\\experimental\\session_cache.py -> python_build\\lib.win-amd64-cpython-311\\grpc\\experimental\n",
      "  copying src\\python\\grpcio\\grpc\\experimental\\__init__.py -> python_build\\lib.win-amd64-cpython-311\\grpc\\experimental\n",
      "  creating python_build\\lib.win-amd64-cpython-311\\grpc\\framework\n",
      "  copying src\\python\\grpcio\\grpc\\framework\\__init__.py -> python_build\\lib.win-amd64-cpython-311\\grpc\\framework\n",
      "  creating python_build\\lib.win-amd64-cpython-311\\grpc\\_cython\n",
      "  copying src\\python\\grpcio\\grpc\\_cython\\__init__.py -> python_build\\lib.win-amd64-cpython-311\\grpc\\_cython\n",
      "  creating python_build\\lib.win-amd64-cpython-311\\grpc\\experimental\\aio\n",
      "  copying src\\python\\grpcio\\grpc\\experimental\\aio\\__init__.py -> python_build\\lib.win-amd64-cpython-311\\grpc\\experimental\\aio\n",
      "  creating python_build\\lib.win-amd64-cpython-311\\grpc\\framework\\common\n",
      "  copying src\\python\\grpcio\\grpc\\framework\\common\\cardinality.py -> python_build\\lib.win-amd64-cpython-311\\grpc\\framework\\common\n",
      "  copying src\\python\\grpcio\\grpc\\framework\\common\\style.py -> python_build\\lib.win-amd64-cpython-311\\grpc\\framework\\common\n",
      "  copying src\\python\\grpcio\\grpc\\framework\\common\\__init__.py -> python_build\\lib.win-amd64-cpython-311\\grpc\\framework\\common\n",
      "  creating python_build\\lib.win-amd64-cpython-311\\grpc\\framework\\foundation\n",
      "  copying src\\python\\grpcio\\grpc\\framework\\foundation\\abandonment.py -> python_build\\lib.win-amd64-cpython-311\\grpc\\framework\\foundation\n",
      "  copying src\\python\\grpcio\\grpc\\framework\\foundation\\callable_util.py -> python_build\\lib.win-amd64-cpython-311\\grpc\\framework\\foundation\n",
      "  copying src\\python\\grpcio\\grpc\\framework\\foundation\\future.py -> python_build\\lib.win-amd64-cpython-311\\grpc\\framework\\foundation\n",
      "  copying src\\python\\grpcio\\grpc\\framework\\foundation\\logging_pool.py -> python_build\\lib.win-amd64-cpython-311\\grpc\\framework\\foundation\n",
      "  copying src\\python\\grpcio\\grpc\\framework\\foundation\\stream.py -> python_build\\lib.win-amd64-cpython-311\\grpc\\framework\\foundation\n",
      "  copying src\\python\\grpcio\\grpc\\framework\\foundation\\stream_util.py -> python_build\\lib.win-amd64-cpython-311\\grpc\\framework\\foundation\n",
      "  copying src\\python\\grpcio\\grpc\\framework\\foundation\\__init__.py -> python_build\\lib.win-amd64-cpython-311\\grpc\\framework\\foundation\n",
      "  creating python_build\\lib.win-amd64-cpython-311\\grpc\\framework\\interfaces\n",
      "  copying src\\python\\grpcio\\grpc\\framework\\interfaces\\__init__.py -> python_build\\lib.win-amd64-cpython-311\\grpc\\framework\\interfaces\n",
      "  creating python_build\\lib.win-amd64-cpython-311\\grpc\\framework\\interfaces\\base\n",
      "  copying src\\python\\grpcio\\grpc\\framework\\interfaces\\base\\base.py -> python_build\\lib.win-amd64-cpython-311\\grpc\\framework\\interfaces\\base\n",
      "  copying src\\python\\grpcio\\grpc\\framework\\interfaces\\base\\utilities.py -> python_build\\lib.win-amd64-cpython-311\\grpc\\framework\\interfaces\\base\n",
      "  copying src\\python\\grpcio\\grpc\\framework\\interfaces\\base\\__init__.py -> python_build\\lib.win-amd64-cpython-311\\grpc\\framework\\interfaces\\base\n",
      "  creating python_build\\lib.win-amd64-cpython-311\\grpc\\framework\\interfaces\\face\n",
      "  copying src\\python\\grpcio\\grpc\\framework\\interfaces\\face\\face.py -> python_build\\lib.win-amd64-cpython-311\\grpc\\framework\\interfaces\\face\n",
      "  copying src\\python\\grpcio\\grpc\\framework\\interfaces\\face\\utilities.py -> python_build\\lib.win-amd64-cpython-311\\grpc\\framework\\interfaces\\face\n",
      "  copying src\\python\\grpcio\\grpc\\framework\\interfaces\\face\\__init__.py -> python_build\\lib.win-amd64-cpython-311\\grpc\\framework\\interfaces\\face\n",
      "  creating python_build\\lib.win-amd64-cpython-311\\grpc\\_cython\\_cygrpc\n",
      "  copying src\\python\\grpcio\\grpc\\_cython\\_cygrpc\\__init__.py -> python_build\\lib.win-amd64-cpython-311\\grpc\\_cython\\_cygrpc\n",
      "  creating python_build\\lib.win-amd64-cpython-311\\grpc\\_cython\\_credentials\n",
      "  copying src\\python\\grpcio\\grpc\\_cython\\_credentials\\roots.pem -> python_build\\lib.win-amd64-cpython-311\\grpc\\_cython\\_credentials\n",
      "  running build_ext\n",
      "  Non-fatal exception:Traceback (most recent call last):\n",
      "    File \"C:\\Users\\Palash Ashok Bhosale\\AppData\\Local\\Temp\\pip-install-zsb3h_y3\\grpcio_d87d3504aca3458991da8152c7bf642a\\src\\python\\grpcio\\commands.py\", line 237, in compiler_ok_with_extra_std\n",
      "      cc_test = subprocess.Popen(['cc', '-x', 'c', '-std=c++11', '-'],\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Users\\Palash Ashok Bhosale\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\subprocess.py\", line 1026, in __init__\n",
      "      self._execute_child(args, executable, preexec_fn, close_fds,\n",
      "    File \"C:\\Users\\Palash Ashok Bhosale\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\subprocess.py\", line 1538, in _execute_child\n",
      "      hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  FileNotFoundError: [WinError 2] The system cannot find the file specified\n",
      "  \n",
      "  Found cython-generated files...\n",
      "  building 'grpc._cython.cygrpc' extension\n",
      "  Traceback (most recent call last):\n",
      "    File \"C:\\Users\\Palash Ashok Bhosale\\AppData\\Local\\Temp\\pip-install-zsb3h_y3\\grpcio_d87d3504aca3458991da8152c7bf642a\\src\\python\\grpcio\\commands.py\", line 282, in build_extensions\n",
      "      build_ext.build_ext.build_extensions(self)\n",
      "    File \"C:\\Users\\Palash Ashok Bhosale\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\setuptools\\_distutils\\command\\build_ext.py\", line 467, in build_extensions\n",
      "      self._build_extensions_serial()\n",
      "    File \"C:\\Users\\Palash Ashok Bhosale\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\setuptools\\_distutils\\command\\build_ext.py\", line 493, in _build_extensions_serial\n",
      "      self.build_extension(ext)\n",
      "    File \"C:\\Users\\Palash Ashok Bhosale\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\setuptools\\command\\build_ext.py\", line 249, in build_extension\n",
      "      _build_ext.build_extension(self, ext)\n",
      "    File \"C:\\Users\\Palash Ashok Bhosale\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\setuptools\\_distutils\\command\\build_ext.py\", line 548, in build_extension\n",
      "      objects = self.compiler.compile(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Users\\Palash Ashok Bhosale\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\setuptools\\_distutils\\_msvccompiler.py\", line 343, in compile\n",
      "      self.initialize()\n",
      "    File \"C:\\Users\\Palash Ashok Bhosale\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\setuptools\\_distutils\\_msvccompiler.py\", line 253, in initialize\n",
      "      vc_env = _get_vc_env(plat_spec)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Users\\Palash Ashok Bhosale\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\setuptools\\msvc.py\", line 233, in msvc14_get_vc_env\n",
      "      return _msvc14_get_vc_env(plat_spec)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Users\\Palash Ashok Bhosale\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\setuptools\\msvc.py\", line 190, in _msvc14_get_vc_env\n",
      "      raise distutils.errors.DistutilsPlatformError(\"Unable to find vcvarsall.bat\")\n",
      "  distutils.errors.DistutilsPlatformError: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "  \n",
      "  During handling of the above exception, another exception occurred:\n",
      "  \n",
      "  Traceback (most recent call last):\n",
      "    File \"<string>\", line 2, in <module>\n",
      "    File \"<pip-setuptools-caller>\", line 34, in <module>\n",
      "    File \"C:\\Users\\Palash Ashok Bhosale\\AppData\\Local\\Temp\\pip-install-zsb3h_y3\\grpcio_d87d3504aca3458991da8152c7bf642a\\setup.py\", line 508, in <module>\n",
      "      setuptools.setup(\n",
      "    File \"C:\\Users\\Palash Ashok Bhosale\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\setuptools\\__init__.py\", line 103, in setup\n",
      "      return distutils.core.setup(**attrs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Users\\Palash Ashok Bhosale\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\setuptools\\_distutils\\core.py\", line 185, in setup\n",
      "      return run_commands(dist)\n",
      "             ^^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Users\\Palash Ashok Bhosale\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\setuptools\\_distutils\\core.py\", line 201, in run_commands\n",
      "      dist.run_commands()\n",
      "    File \"C:\\Users\\Palash Ashok Bhosale\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\setuptools\\_distutils\\dist.py\", line 969, in run_commands\n",
      "      self.run_command(cmd)\n",
      "    File \"C:\\Users\\Palash Ashok Bhosale\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\setuptools\\dist.py\", line 989, in run_command\n",
      "      super().run_command(command)\n",
      "    File \"C:\\Users\\Palash Ashok Bhosale\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\setuptools\\_distutils\\dist.py\", line 988, in run_command\n",
      "      cmd_obj.run()\n",
      "    File \"C:\\Users\\Palash Ashok Bhosale\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wheel\\bdist_wheel.py\", line 369, in run\n",
      "      self.run_command(\"build\")\n",
      "    File \"C:\\Users\\Palash Ashok Bhosale\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\setuptools\\_distutils\\cmd.py\", line 318, in run_command\n",
      "      self.distribution.run_command(command)\n",
      "    File \"C:\\Users\\Palash Ashok Bhosale\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\setuptools\\dist.py\", line 989, in run_command\n",
      "      super().run_command(command)\n",
      "    File \"C:\\Users\\Palash Ashok Bhosale\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\setuptools\\_distutils\\dist.py\", line 988, in run_command\n",
      "      cmd_obj.run()\n",
      "    File \"C:\\Users\\Palash Ashok Bhosale\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\setuptools\\_distutils\\command\\build.py\", line 131, in run\n",
      "      self.run_command(cmd_name)\n",
      "    File \"C:\\Users\\Palash Ashok Bhosale\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\setuptools\\_distutils\\cmd.py\", line 318, in run_command\n",
      "      self.distribution.run_command(command)\n",
      "    File \"C:\\Users\\Palash Ashok Bhosale\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\setuptools\\dist.py\", line 989, in run_command\n",
      "      super().run_command(command)\n",
      "    File \"C:\\Users\\Palash Ashok Bhosale\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\setuptools\\_distutils\\dist.py\", line 988, in run_command\n",
      "      cmd_obj.run()\n",
      "    File \"C:\\Users\\Palash Ashok Bhosale\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\setuptools\\command\\build_ext.py\", line 88, in run\n",
      "      _build_ext.run(self)\n",
      "    File \"C:\\Users\\Palash Ashok Bhosale\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\setuptools\\_distutils\\command\\build_ext.py\", line 345, in run\n",
      "      self.build_extensions()\n",
      "    File \"C:\\Users\\Palash Ashok Bhosale\\AppData\\Local\\Temp\\pip-install-zsb3h_y3\\grpcio_d87d3504aca3458991da8152c7bf642a\\src\\python\\grpcio\\commands.py\", line 285, in build_extensions\n",
      "      support.diagnose_build_ext_error(self, error, formatted_exception)\n",
      "    File \"C:\\Users\\Palash Ashok Bhosale\\AppData\\Local\\Temp\\pip-install-zsb3h_y3\\grpcio_d87d3504aca3458991da8152c7bf642a\\src\\python\\grpcio\\support.py\", line 111, in diagnose_build_ext_error\n",
      "      raise commands.CommandError(\n",
      "  commands.CommandError:\n",
      "  \n",
      "  We could not diagnose your build failure. If you are unable to proceed, please file an issue at http://www.github.com/grpc/grpc with `[Python install]` in the title; please attach the whole log (including everything that may have appeared above the Python backtrace).\n",
      "  \n",
      "  Traceback (most recent call last):\n",
      "    File \"C:\\Users\\Palash Ashok Bhosale\\AppData\\Local\\Temp\\pip-install-zsb3h_y3\\grpcio_d87d3504aca3458991da8152c7bf642a\\src\\python\\grpcio\\commands.py\", line 282, in build_extensions\n",
      "      build_ext.build_ext.build_extensions(self)\n",
      "    File \"C:\\Users\\Palash Ashok Bhosale\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\setuptools\\_distutils\\command\\build_ext.py\", line 467, in build_extensions\n",
      "      self._build_extensions_serial()\n",
      "    File \"C:\\Users\\Palash Ashok Bhosale\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\setuptools\\_distutils\\command\\build_ext.py\", line 493, in _build_extensions_serial\n",
      "      self.build_extension(ext)\n",
      "    File \"C:\\Users\\Palash Ashok Bhosale\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\setuptools\\command\\build_ext.py\", line 249, in build_extension\n",
      "      _build_ext.build_extension(self, ext)\n",
      "    File \"C:\\Users\\Palash Ashok Bhosale\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\setuptools\\_distutils\\command\\build_ext.py\", line 548, in build_extension\n",
      "      objects = self.compiler.compile(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Users\\Palash Ashok Bhosale\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\setuptools\\_distutils\\_msvccompiler.py\", line 343, in compile\n",
      "      self.initialize()\n",
      "    File \"C:\\Users\\Palash Ashok Bhosale\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\setuptools\\_distutils\\_msvccompiler.py\", line 253, in initialize\n",
      "      vc_env = _get_vc_env(plat_spec)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Users\\Palash Ashok Bhosale\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\setuptools\\msvc.py\", line 233, in msvc14_get_vc_env\n",
      "      return _msvc14_get_vc_env(plat_spec)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Users\\Palash Ashok Bhosale\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\setuptools\\msvc.py\", line 190, in _msvc14_get_vc_env\n",
      "      raise distutils.errors.DistutilsPlatformError(\"Unable to find vcvarsall.bat\")\n",
      "  distutils.errors.DistutilsPlatformError: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "  \n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for grpcio\n",
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  python setup.py bdist_wheel did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [30 lines of output]\n",
      "  C:\\Users\\Palash Ashok Bhosale\\AppData\\Local\\Temp\\pip-install-zsb3h_y3\\grpcio-tools_eef2069937854a46bcc87792c12ead79\\setup.py:21: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n",
      "    import pkg_resources\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\n",
      "  creating build\\lib.win-amd64-cpython-311\n",
      "  creating build\\lib.win-amd64-cpython-311\\grpc_tools\n",
      "  copying grpc_tools\\command.py -> build\\lib.win-amd64-cpython-311\\grpc_tools\n",
      "  copying grpc_tools\\protoc.py -> build\\lib.win-amd64-cpython-311\\grpc_tools\n",
      "  copying grpc_tools\\__init__.py -> build\\lib.win-amd64-cpython-311\\grpc_tools\n",
      "  creating build\\lib.win-amd64-cpython-311\\grpc_tools\\_proto\n",
      "  creating build\\lib.win-amd64-cpython-311\\grpc_tools\\_proto\\google\n",
      "  creating build\\lib.win-amd64-cpython-311\\grpc_tools\\_proto\\google\\protobuf\n",
      "  copying grpc_tools\\_proto\\google\\protobuf\\wrappers.proto -> build\\lib.win-amd64-cpython-311\\grpc_tools\\_proto\\google\\protobuf\n",
      "  copying grpc_tools\\_proto\\google\\protobuf\\type.proto -> build\\lib.win-amd64-cpython-311\\grpc_tools\\_proto\\google\\protobuf\n",
      "  copying grpc_tools\\_proto\\google\\protobuf\\timestamp.proto -> build\\lib.win-amd64-cpython-311\\grpc_tools\\_proto\\google\\protobuf\n",
      "  copying grpc_tools\\_proto\\google\\protobuf\\struct.proto -> build\\lib.win-amd64-cpython-311\\grpc_tools\\_proto\\google\\protobuf\n",
      "  copying grpc_tools\\_proto\\google\\protobuf\\source_context.proto -> build\\lib.win-amd64-cpython-311\\grpc_tools\\_proto\\google\\protobuf\n",
      "  copying grpc_tools\\_proto\\google\\protobuf\\field_mask.proto -> build\\lib.win-amd64-cpython-311\\grpc_tools\\_proto\\google\\protobuf\n",
      "  copying grpc_tools\\_proto\\google\\protobuf\\empty.proto -> build\\lib.win-amd64-cpython-311\\grpc_tools\\_proto\\google\\protobuf\n",
      "  copying grpc_tools\\_proto\\google\\protobuf\\duration.proto -> build\\lib.win-amd64-cpython-311\\grpc_tools\\_proto\\google\\protobuf\n",
      "  copying grpc_tools\\_proto\\google\\protobuf\\descriptor.proto -> build\\lib.win-amd64-cpython-311\\grpc_tools\\_proto\\google\\protobuf\n",
      "  creating build\\lib.win-amd64-cpython-311\\grpc_tools\\_proto\\google\\protobuf\\compiler\n",
      "  copying grpc_tools\\_proto\\google\\protobuf\\compiler\\plugin.proto -> build\\lib.win-amd64-cpython-311\\grpc_tools\\_proto\\google\\protobuf\\compiler\n",
      "  copying grpc_tools\\_proto\\google\\protobuf\\api.proto -> build\\lib.win-amd64-cpython-311\\grpc_tools\\_proto\\google\\protobuf\n",
      "  copying grpc_tools\\_proto\\google\\protobuf\\any.proto -> build\\lib.win-amd64-cpython-311\\grpc_tools\\_proto\\google\\protobuf\n",
      "  running build_ext\n",
      "  building 'grpc_tools._protoc_compiler' extension\n",
      "  error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for grpcio-tools\n",
      "ERROR: Could not build wheels for grpcio, grpcio-tools, which is required to install pyproject.toml-based projects\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pymilvus==1.1.2\n",
      "  Using cached pymilvus-1.1.2-py3-none-any.whl (56 kB)\n",
      "Collecting grpcio<1.38.0,>=1.22.0 (from pymilvus==1.1.2)\n",
      "  Using cached grpcio-1.37.1.tar.gz (21.7 MB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting grpcio-tools<1.38.0,>=1.22.0 (from pymilvus==1.1.2)\n",
      "  Using cached grpcio-tools-1.37.1.tar.gz (2.1 MB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: requests>=2.22.0 in c:\\users\\palash ashok bhosale\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pymilvus==1.1.2) (2.31.0)\n",
      "Requirement already satisfied: ujson>=2.0.0 in c:\\users\\palash ashok bhosale\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pymilvus==1.1.2) (5.8.0)\n",
      "Requirement already satisfied: six>=1.5.2 in c:\\users\\palash ashok bhosale\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from grpcio<1.38.0,>=1.22.0->pymilvus==1.1.2) (1.16.0)\n",
      "Collecting protobuf<4.0dev,>=3.5.0.post1 (from grpcio-tools<1.38.0,>=1.22.0->pymilvus==1.1.2)\n",
      "  Using cached protobuf-3.20.3-py2.py3-none-any.whl (162 kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\palash ashok bhosale\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from grpcio-tools<1.38.0,>=1.22.0->pymilvus==1.1.2) (68.2.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\palash ashok bhosale\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.22.0->pymilvus==1.1.2) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\palash ashok bhosale\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.22.0->pymilvus==1.1.2) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\palash ashok bhosale\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.22.0->pymilvus==1.1.2) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\palash ashok bhosale\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.22.0->pymilvus==1.1.2) (2023.5.7)\n",
      "Building wheels for collected packages: grpcio, grpcio-tools\n",
      "  Building wheel for grpcio (setup.py): started\n",
      "  Building wheel for grpcio (setup.py): finished with status 'error'\n",
      "  Running setup.py clean for grpcio\n",
      "  Building wheel for grpcio-tools (setup.py): started\n",
      "  Building wheel for grpcio-tools (setup.py): finished with status 'error'\n",
      "  Running setup.py clean for grpcio-tools\n",
      "Failed to build grpcio grpcio-tools\n",
      "Collecting pymilvus==1.1.2\n",
      "  Using cached pymilvus-1.1.2-py3-none-any.whl (56 kB)\n",
      "Collecting grpcio<1.38.0,>=1.22.0 (from pymilvus==1.1.2)\n",
      "  Using cached grpcio-1.37.1.tar.gz (21.7 MB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting grpcio-tools<1.38.0,>=1.22.0 (from pymilvus==1.1.2)\n",
      "  Using cached grpcio-tools-1.37.1.tar.gz (2.1 MB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: requests>=2.22.0 in c:\\users\\palash ashok bhosale\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pymilvus==1.1.2) (2.31.0)\n",
      "Requirement already satisfied: ujson>=2.0.0 in c:\\users\\palash ashok bhosale\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pymilvus==1.1.2) (5.8.0)\n",
      "Requirement already satisfied: six>=1.5.2 in c:\\users\\palash ashok bhosale\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from grpcio<1.38.0,>=1.22.0->pymilvus==1.1.2) (1.16.0)\n",
      "Collecting protobuf<4.0dev,>=3.5.0.post1 (from grpcio-tools<1.38.0,>=1.22.0->pymilvus==1.1.2)\n",
      "  Using cached protobuf-3.20.3-py2.py3-none-any.whl (162 kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\palash ashok bhosale\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from grpcio-tools<1.38.0,>=1.22.0->pymilvus==1.1.2) (68.2.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\palash ashok bhosale\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.22.0->pymilvus==1.1.2) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\palash ashok bhosale\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.22.0->pymilvus==1.1.2) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\palash ashok bhosale\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.22.0->pymilvus==1.1.2) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\palash ashok bhosale\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.22.0->pymilvus==1.1.2) (2023.5.7)\n",
      "Building wheels for collected packages: grpcio, grpcio-tools\n",
      "  Building wheel for grpcio (setup.py): started\n",
      "  Building wheel for grpcio (setup.py): finished with status 'error'\n",
      "  Running setup.py clean for grpcio\n",
      "  Building wheel for grpcio-tools (setup.py): started\n",
      "  Building wheel for grpcio-tools (setup.py): finished with status 'error'\n",
      "  Running setup.py clean for grpcio-tools\n",
      "Failed to build grpcio grpcio-tools\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  python setup.py bdist_wheel did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [190 lines of output]\n",
      "  C:\\Users\\Palash Ashok Bhosale\\AppData\\Local\\Temp\\pip-install-icbvvw3_\\grpcio_208ae9df8f4b4e30bdb6bd4de2858137\\setup.py:31: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n",
      "    import pkg_resources\n",
      "  ASM Builds for BoringSSL currently not supported on: win-amd64\n",
      "  Found cython-generated files...\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  running build_project_metadata\n",
      "  creating python_build\n",
      "  creating python_build\\lib.win-amd64-cpython-311\n",
      "  creating python_build\\lib.win-amd64-cpython-311\\grpc\n",
      "  copying src\\python\\grpcio\\grpc\\_auth.py -> python_build\\lib.win-amd64-cpython-311\\grpc\n",
      "  copying src\\python\\grpcio\\grpc\\_channel.py -> python_build\\lib.win-amd64-cpython-311\\grpc\n",
      "  copying src\\python\\grpcio\\grpc\\_common.py -> python_build\\lib.win-amd64-cpython-311\\grpc\n",
      "  copying src\\python\\grpcio\\grpc\\_compression.py -> python_build\\lib.win-amd64-cpython-311\\grpc\n",
      "  copying src\\python\\grpcio\\grpc\\_grpcio_metadata.py -> python_build\\lib.win-amd64-cpython-311\\grpc\n",
      "  copying src\\python\\grpcio\\grpc\\_interceptor.py -> python_build\\lib.win-amd64-cpython-311\\grpc\n",
      "  copying src\\python\\grpcio\\grpc\\_plugin_wrapping.py -> python_build\\lib.win-amd64-cpython-311\\grpc\n",
      "  copying src\\python\\grpcio\\grpc\\_runtime_protos.py -> python_build\\lib.win-amd64-cpython-311\\grpc\n",
      "  copying src\\python\\grpcio\\grpc\\_server.py -> python_build\\lib.win-amd64-cpython-311\\grpc\n",
      "  copying src\\python\\grpcio\\grpc\\_simple_stubs.py -> python_build\\lib.win-amd64-cpython-311\\grpc\n",
      "  copying src\\python\\grpcio\\grpc\\_utilities.py -> python_build\\lib.win-amd64-cpython-311\\grpc\n",
      "  copying src\\python\\grpcio\\grpc\\__init__.py -> python_build\\lib.win-amd64-cpython-311\\grpc\n",
      "  creating python_build\\lib.win-amd64-cpython-311\\grpc\\aio\n",
      "  copying src\\python\\grpcio\\grpc\\aio\\_base_call.py -> python_build\\lib.win-amd64-cpython-311\\grpc\\aio\n",
      "  copying src\\python\\grpcio\\grpc\\aio\\_base_channel.py -> python_build\\lib.win-amd64-cpython-311\\grpc\\aio\n",
      "  copying src\\python\\grpcio\\grpc\\aio\\_base_server.py -> python_build\\lib.win-amd64-cpython-311\\grpc\\aio\n",
      "  copying src\\python\\grpcio\\grpc\\aio\\_call.py -> python_build\\lib.win-amd64-cpython-311\\grpc\\aio\n",
      "  copying src\\python\\grpcio\\grpc\\aio\\_channel.py -> python_build\\lib.win-amd64-cpython-311\\grpc\\aio\n",
      "  copying src\\python\\grpcio\\grpc\\aio\\_interceptor.py -> python_build\\lib.win-amd64-cpython-311\\grpc\\aio\n",
      "  copying src\\python\\grpcio\\grpc\\aio\\_metadata.py -> python_build\\lib.win-amd64-cpython-311\\grpc\\aio\n",
      "  copying src\\python\\grpcio\\grpc\\aio\\_server.py -> python_build\\lib.win-amd64-cpython-311\\grpc\\aio\n",
      "  copying src\\python\\grpcio\\grpc\\aio\\_typing.py -> python_build\\lib.win-amd64-cpython-311\\grpc\\aio\n",
      "  copying src\\python\\grpcio\\grpc\\aio\\_utils.py -> python_build\\lib.win-amd64-cpython-311\\grpc\\aio\n",
      "  copying src\\python\\grpcio\\grpc\\aio\\__init__.py -> python_build\\lib.win-amd64-cpython-311\\grpc\\aio\n",
      "  creating python_build\\lib.win-amd64-cpython-311\\grpc\\beta\n",
      "  copying src\\python\\grpcio\\grpc\\beta\\implementations.py -> python_build\\lib.win-amd64-cpython-311\\grpc\\beta\n",
      "  copying src\\python\\grpcio\\grpc\\beta\\interfaces.py -> python_build\\lib.win-amd64-cpython-311\\grpc\\beta\n",
      "  copying src\\python\\grpcio\\grpc\\beta\\utilities.py -> python_build\\lib.win-amd64-cpython-311\\grpc\\beta\n",
      "  copying src\\python\\grpcio\\grpc\\beta\\_client_adaptations.py -> python_build\\lib.win-amd64-cpython-311\\grpc\\beta\n",
      "  copying src\\python\\grpcio\\grpc\\beta\\_metadata.py -> python_build\\lib.win-amd64-cpython-311\\grpc\\beta\n",
      "  copying src\\python\\grpcio\\grpc\\beta\\_server_adaptations.py -> python_build\\lib.win-amd64-cpython-311\\grpc\\beta\n",
      "  copying src\\python\\grpcio\\grpc\\beta\\__init__.py -> python_build\\lib.win-amd64-cpython-311\\grpc\\beta\n",
      "  creating python_build\\lib.win-amd64-cpython-311\\grpc\\experimental\n",
      "  copying src\\python\\grpcio\\grpc\\experimental\\gevent.py -> python_build\\lib.win-amd64-cpython-311\\grpc\\experimental\n",
      "  copying src\\python\\grpcio\\grpc\\experimental\\session_cache.py -> python_build\\lib.win-amd64-cpython-311\\grpc\\experimental\n",
      "  copying src\\python\\grpcio\\grpc\\experimental\\__init__.py -> python_build\\lib.win-amd64-cpython-311\\grpc\\experimental\n",
      "  creating python_build\\lib.win-amd64-cpython-311\\grpc\\framework\n",
      "  copying src\\python\\grpcio\\grpc\\framework\\__init__.py -> python_build\\lib.win-amd64-cpython-311\\grpc\\framework\n",
      "  creating python_build\\lib.win-amd64-cpython-311\\grpc\\_cython\n",
      "  copying src\\python\\grpcio\\grpc\\_cython\\__init__.py -> python_build\\lib.win-amd64-cpython-311\\grpc\\_cython\n",
      "  creating python_build\\lib.win-amd64-cpython-311\\grpc\\experimental\\aio\n",
      "  copying src\\python\\grpcio\\grpc\\experimental\\aio\\__init__.py -> python_build\\lib.win-amd64-cpython-311\\grpc\\experimental\\aio\n",
      "  creating python_build\\lib.win-amd64-cpython-311\\grpc\\framework\\common\n",
      "  copying src\\python\\grpcio\\grpc\\framework\\common\\cardinality.py -> python_build\\lib.win-amd64-cpython-311\\grpc\\framework\\common\n",
      "  copying src\\python\\grpcio\\grpc\\framework\\common\\style.py -> python_build\\lib.win-amd64-cpython-311\\grpc\\framework\\common\n",
      "  copying src\\python\\grpcio\\grpc\\framework\\common\\__init__.py -> python_build\\lib.win-amd64-cpython-311\\grpc\\framework\\common\n",
      "  creating python_build\\lib.win-amd64-cpython-311\\grpc\\framework\\foundation\n",
      "  copying src\\python\\grpcio\\grpc\\framework\\foundation\\abandonment.py -> python_build\\lib.win-amd64-cpython-311\\grpc\\framework\\foundation\n",
      "  copying src\\python\\grpcio\\grpc\\framework\\foundation\\callable_util.py -> python_build\\lib.win-amd64-cpython-311\\grpc\\framework\\foundation\n",
      "  copying src\\python\\grpcio\\grpc\\framework\\foundation\\future.py -> python_build\\lib.win-amd64-cpython-311\\grpc\\framework\\foundation\n",
      "  copying src\\python\\grpcio\\grpc\\framework\\foundation\\logging_pool.py -> python_build\\lib.win-amd64-cpython-311\\grpc\\framework\\foundation\n",
      "  copying src\\python\\grpcio\\grpc\\framework\\foundation\\stream.py -> python_build\\lib.win-amd64-cpython-311\\grpc\\framework\\foundation\n",
      "  copying src\\python\\grpcio\\grpc\\framework\\foundation\\stream_util.py -> python_build\\lib.win-amd64-cpython-311\\grpc\\framework\\foundation\n",
      "  copying src\\python\\grpcio\\grpc\\framework\\foundation\\__init__.py -> python_build\\lib.win-amd64-cpython-311\\grpc\\framework\\foundation\n",
      "  creating python_build\\lib.win-amd64-cpython-311\\grpc\\framework\\interfaces\n",
      "  copying src\\python\\grpcio\\grpc\\framework\\interfaces\\__init__.py -> python_build\\lib.win-amd64-cpython-311\\grpc\\framework\\interfaces\n",
      "  creating python_build\\lib.win-amd64-cpython-311\\grpc\\framework\\interfaces\\base\n",
      "  copying src\\python\\grpcio\\grpc\\framework\\interfaces\\base\\base.py -> python_build\\lib.win-amd64-cpython-311\\grpc\\framework\\interfaces\\base\n",
      "  copying src\\python\\grpcio\\grpc\\framework\\interfaces\\base\\utilities.py -> python_build\\lib.win-amd64-cpython-311\\grpc\\framework\\interfaces\\base\n",
      "  copying src\\python\\grpcio\\grpc\\framework\\interfaces\\base\\__init__.py -> python_build\\lib.win-amd64-cpython-311\\grpc\\framework\\interfaces\\base\n",
      "  creating python_build\\lib.win-amd64-cpython-311\\grpc\\framework\\interfaces\\face\n",
      "  copying src\\python\\grpcio\\grpc\\framework\\interfaces\\face\\face.py -> python_build\\lib.win-amd64-cpython-311\\grpc\\framework\\interfaces\\face\n",
      "  copying src\\python\\grpcio\\grpc\\framework\\interfaces\\face\\utilities.py -> python_build\\lib.win-amd64-cpython-311\\grpc\\framework\\interfaces\\face\n",
      "  copying src\\python\\grpcio\\grpc\\framework\\interfaces\\face\\__init__.py -> python_build\\lib.win-amd64-cpython-311\\grpc\\framework\\interfaces\\face\n",
      "  creating python_build\\lib.win-amd64-cpython-311\\grpc\\_cython\\_cygrpc\n",
      "  copying src\\python\\grpcio\\grpc\\_cython\\_cygrpc\\__init__.py -> python_build\\lib.win-amd64-cpython-311\\grpc\\_cython\\_cygrpc\n",
      "  creating python_build\\lib.win-amd64-cpython-311\\grpc\\_cython\\_credentials\n",
      "  copying src\\python\\grpcio\\grpc\\_cython\\_credentials\\roots.pem -> python_build\\lib.win-amd64-cpython-311\\grpc\\_cython\\_credentials\n",
      "  running build_ext\n",
      "  Non-fatal exception:Traceback (most recent call last):\n",
      "    File \"C:\\Users\\Palash Ashok Bhosale\\AppData\\Local\\Temp\\pip-install-icbvvw3_\\grpcio_208ae9df8f4b4e30bdb6bd4de2858137\\src\\python\\grpcio\\commands.py\", line 237, in compiler_ok_with_extra_std\n",
      "      cc_test = subprocess.Popen(['cc', '-x', 'c', '-std=c++11', '-'],\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Users\\Palash Ashok Bhosale\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\subprocess.py\", line 1026, in __init__\n",
      "      self._execute_child(args, executable, preexec_fn, close_fds,\n",
      "    File \"C:\\Users\\Palash Ashok Bhosale\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\subprocess.py\", line 1538, in _execute_child\n",
      "      hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  FileNotFoundError: [WinError 2] The system cannot find the file specified\n",
      "  \n",
      "  Found cython-generated files...\n",
      "  building 'grpc._cython.cygrpc' extension\n",
      "  Traceback (most recent call last):\n",
      "    File \"C:\\Users\\Palash Ashok Bhosale\\AppData\\Local\\Temp\\pip-install-icbvvw3_\\grpcio_208ae9df8f4b4e30bdb6bd4de2858137\\src\\python\\grpcio\\commands.py\", line 282, in build_extensions\n",
      "      build_ext.build_ext.build_extensions(self)\n",
      "    File \"C:\\Users\\Palash Ashok Bhosale\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\setuptools\\_distutils\\command\\build_ext.py\", line 467, in build_extensions\n",
      "      self._build_extensions_serial()\n",
      "    File \"C:\\Users\\Palash Ashok Bhosale\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\setuptools\\_distutils\\command\\build_ext.py\", line 493, in _build_extensions_serial\n",
      "      self.build_extension(ext)\n",
      "    File \"C:\\Users\\Palash Ashok Bhosale\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\setuptools\\command\\build_ext.py\", line 249, in build_extension\n",
      "      _build_ext.build_extension(self, ext)\n",
      "    File \"C:\\Users\\Palash Ashok Bhosale\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\setuptools\\_distutils\\command\\build_ext.py\", line 548, in build_extension\n",
      "      objects = self.compiler.compile(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Users\\Palash Ashok Bhosale\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\setuptools\\_distutils\\_msvccompiler.py\", line 343, in compile\n",
      "      self.initialize()\n",
      "    File \"C:\\Users\\Palash Ashok Bhosale\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\setuptools\\_distutils\\_msvccompiler.py\", line 253, in initialize\n",
      "      vc_env = _get_vc_env(plat_spec)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Users\\Palash Ashok Bhosale\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\setuptools\\msvc.py\", line 233, in msvc14_get_vc_env\n",
      "      return _msvc14_get_vc_env(plat_spec)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Users\\Palash Ashok Bhosale\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\setuptools\\msvc.py\", line 190, in _msvc14_get_vc_env\n",
      "      raise distutils.errors.DistutilsPlatformError(\"Unable to find vcvarsall.bat\")\n",
      "  distutils.errors.DistutilsPlatformError: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "  \n",
      "  During handling of the above exception, another exception occurred:\n",
      "  \n",
      "  Traceback (most recent call last):\n",
      "    File \"<string>\", line 2, in <module>\n",
      "    File \"<pip-setuptools-caller>\", line 34, in <module>\n",
      "    File \"C:\\Users\\Palash Ashok Bhosale\\AppData\\Local\\Temp\\pip-install-icbvvw3_\\grpcio_208ae9df8f4b4e30bdb6bd4de2858137\\setup.py\", line 508, in <module>\n",
      "      setuptools.setup(\n",
      "    File \"C:\\Users\\Palash Ashok Bhosale\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\setuptools\\__init__.py\", line 103, in setup\n",
      "      return distutils.core.setup(**attrs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Users\\Palash Ashok Bhosale\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\setuptools\\_distutils\\core.py\", line 185, in setup\n",
      "      return run_commands(dist)\n",
      "             ^^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Users\\Palash Ashok Bhosale\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\setuptools\\_distutils\\core.py\", line 201, in run_commands\n",
      "      dist.run_commands()\n",
      "    File \"C:\\Users\\Palash Ashok Bhosale\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\setuptools\\_distutils\\dist.py\", line 969, in run_commands\n",
      "      self.run_command(cmd)\n",
      "    File \"C:\\Users\\Palash Ashok Bhosale\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\setuptools\\dist.py\", line 989, in run_command\n",
      "      super().run_command(command)\n",
      "    File \"C:\\Users\\Palash Ashok Bhosale\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\setuptools\\_distutils\\dist.py\", line 988, in run_command\n",
      "      cmd_obj.run()\n",
      "    File \"C:\\Users\\Palash Ashok Bhosale\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wheel\\bdist_wheel.py\", line 369, in run\n",
      "      self.run_command(\"build\")\n",
      "    File \"C:\\Users\\Palash Ashok Bhosale\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\setuptools\\_distutils\\cmd.py\", line 318, in run_command\n",
      "      self.distribution.run_command(command)\n",
      "    File \"C:\\Users\\Palash Ashok Bhosale\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\setuptools\\dist.py\", line 989, in run_command\n",
      "      super().run_command(command)\n",
      "    File \"C:\\Users\\Palash Ashok Bhosale\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\setuptools\\_distutils\\dist.py\", line 988, in run_command\n",
      "      cmd_obj.run()\n",
      "    File \"C:\\Users\\Palash Ashok Bhosale\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\setuptools\\_distutils\\command\\build.py\", line 131, in run\n",
      "      self.run_command(cmd_name)\n",
      "    File \"C:\\Users\\Palash Ashok Bhosale\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\setuptools\\_distutils\\cmd.py\", line 318, in run_command\n",
      "      self.distribution.run_command(command)\n",
      "    File \"C:\\Users\\Palash Ashok Bhosale\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\setuptools\\dist.py\", line 989, in run_command\n",
      "      super().run_command(command)\n",
      "    File \"C:\\Users\\Palash Ashok Bhosale\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\setuptools\\_distutils\\dist.py\", line 988, in run_command\n",
      "      cmd_obj.run()\n",
      "    File \"C:\\Users\\Palash Ashok Bhosale\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\setuptools\\command\\build_ext.py\", line 88, in run\n",
      "      _build_ext.run(self)\n",
      "    File \"C:\\Users\\Palash Ashok Bhosale\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\setuptools\\_distutils\\command\\build_ext.py\", line 345, in run\n",
      "      self.build_extensions()\n",
      "    File \"C:\\Users\\Palash Ashok Bhosale\\AppData\\Local\\Temp\\pip-install-icbvvw3_\\grpcio_208ae9df8f4b4e30bdb6bd4de2858137\\src\\python\\grpcio\\commands.py\", line 285, in build_extensions\n",
      "      support.diagnose_build_ext_error(self, error, formatted_exception)\n",
      "    File \"C:\\Users\\Palash Ashok Bhosale\\AppData\\Local\\Temp\\pip-install-icbvvw3_\\grpcio_208ae9df8f4b4e30bdb6bd4de2858137\\src\\python\\grpcio\\support.py\", line 111, in diagnose_build_ext_error\n",
      "      raise commands.CommandError(\n",
      "  commands.CommandError:\n",
      "  \n",
      "  We could not diagnose your build failure. If you are unable to proceed, please file an issue at http://www.github.com/grpc/grpc with `[Python install]` in the title; please attach the whole log (including everything that may have appeared above the Python backtrace).\n",
      "  \n",
      "  Traceback (most recent call last):\n",
      "    File \"C:\\Users\\Palash Ashok Bhosale\\AppData\\Local\\Temp\\pip-install-icbvvw3_\\grpcio_208ae9df8f4b4e30bdb6bd4de2858137\\src\\python\\grpcio\\commands.py\", line 282, in build_extensions\n",
      "      build_ext.build_ext.build_extensions(self)\n",
      "    File \"C:\\Users\\Palash Ashok Bhosale\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\setuptools\\_distutils\\command\\build_ext.py\", line 467, in build_extensions\n",
      "      self._build_extensions_serial()\n",
      "    File \"C:\\Users\\Palash Ashok Bhosale\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\setuptools\\_distutils\\command\\build_ext.py\", line 493, in _build_extensions_serial\n",
      "      self.build_extension(ext)\n",
      "    File \"C:\\Users\\Palash Ashok Bhosale\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\setuptools\\command\\build_ext.py\", line 249, in build_extension\n",
      "      _build_ext.build_extension(self, ext)\n",
      "    File \"C:\\Users\\Palash Ashok Bhosale\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\setuptools\\_distutils\\command\\build_ext.py\", line 548, in build_extension\n",
      "      objects = self.compiler.compile(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Users\\Palash Ashok Bhosale\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\setuptools\\_distutils\\_msvccompiler.py\", line 343, in compile\n",
      "      self.initialize()\n",
      "    File \"C:\\Users\\Palash Ashok Bhosale\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\setuptools\\_distutils\\_msvccompiler.py\", line 253, in initialize\n",
      "      vc_env = _get_vc_env(plat_spec)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Users\\Palash Ashok Bhosale\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\setuptools\\msvc.py\", line 233, in msvc14_get_vc_env\n",
      "      return _msvc14_get_vc_env(plat_spec)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Users\\Palash Ashok Bhosale\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\setuptools\\msvc.py\", line 190, in _msvc14_get_vc_env\n",
      "      raise distutils.errors.DistutilsPlatformError(\"Unable to find vcvarsall.bat\")\n",
      "  distutils.errors.DistutilsPlatformError: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "  \n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for grpcio\n",
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  python setup.py bdist_wheel did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [30 lines of output]\n",
      "  C:\\Users\\Palash Ashok Bhosale\\AppData\\Local\\Temp\\pip-install-icbvvw3_\\grpcio-tools_d0d910a5cb7c4dc081afc002ec73cd0a\\setup.py:21: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n",
      "    import pkg_resources\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\n",
      "  creating build\\lib.win-amd64-cpython-311\n",
      "  creating build\\lib.win-amd64-cpython-311\\grpc_tools\n",
      "  copying grpc_tools\\command.py -> build\\lib.win-amd64-cpython-311\\grpc_tools\n",
      "  copying grpc_tools\\protoc.py -> build\\lib.win-amd64-cpython-311\\grpc_tools\n",
      "  copying grpc_tools\\__init__.py -> build\\lib.win-amd64-cpython-311\\grpc_tools\n",
      "  creating build\\lib.win-amd64-cpython-311\\grpc_tools\\_proto\n",
      "  creating build\\lib.win-amd64-cpython-311\\grpc_tools\\_proto\\google\n",
      "  creating build\\lib.win-amd64-cpython-311\\grpc_tools\\_proto\\google\\protobuf\n",
      "  copying grpc_tools\\_proto\\google\\protobuf\\wrappers.proto -> build\\lib.win-amd64-cpython-311\\grpc_tools\\_proto\\google\\protobuf\n",
      "  copying grpc_tools\\_proto\\google\\protobuf\\type.proto -> build\\lib.win-amd64-cpython-311\\grpc_tools\\_proto\\google\\protobuf\n",
      "  copying grpc_tools\\_proto\\google\\protobuf\\timestamp.proto -> build\\lib.win-amd64-cpython-311\\grpc_tools\\_proto\\google\\protobuf\n",
      "  copying grpc_tools\\_proto\\google\\protobuf\\struct.proto -> build\\lib.win-amd64-cpython-311\\grpc_tools\\_proto\\google\\protobuf\n",
      "  copying grpc_tools\\_proto\\google\\protobuf\\source_context.proto -> build\\lib.win-amd64-cpython-311\\grpc_tools\\_proto\\google\\protobuf\n",
      "  copying grpc_tools\\_proto\\google\\protobuf\\field_mask.proto -> build\\lib.win-amd64-cpython-311\\grpc_tools\\_proto\\google\\protobuf\n",
      "  copying grpc_tools\\_proto\\google\\protobuf\\empty.proto -> build\\lib.win-amd64-cpython-311\\grpc_tools\\_proto\\google\\protobuf\n",
      "  copying grpc_tools\\_proto\\google\\protobuf\\duration.proto -> build\\lib.win-amd64-cpython-311\\grpc_tools\\_proto\\google\\protobuf\n",
      "  copying grpc_tools\\_proto\\google\\protobuf\\descriptor.proto -> build\\lib.win-amd64-cpython-311\\grpc_tools\\_proto\\google\\protobuf\n",
      "  creating build\\lib.win-amd64-cpython-311\\grpc_tools\\_proto\\google\\protobuf\\compiler\n",
      "  copying grpc_tools\\_proto\\google\\protobuf\\compiler\\plugin.proto -> build\\lib.win-amd64-cpython-311\\grpc_tools\\_proto\\google\\protobuf\\compiler\n",
      "  copying grpc_tools\\_proto\\google\\protobuf\\api.proto -> build\\lib.win-amd64-cpython-311\\grpc_tools\\_proto\\google\\protobuf\n",
      "  copying grpc_tools\\_proto\\google\\protobuf\\any.proto -> build\\lib.win-amd64-cpython-311\\grpc_tools\\_proto\\google\\protobuf\n",
      "  running build_ext\n",
      "  building 'grpc_tools._protoc_compiler' extension\n",
      "  error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for grpcio-tools\n",
      "ERROR: Could not build wheels for grpcio, grpcio-tools, which is required to install pyproject.toml-based projects\n"
     ]
    }
   ],
   "source": [
    "# pip install pymilvus==1.1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf34673a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from milvus import Milvus, DataType, MetricType\n",
    "import milvus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d9c1e35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "path=r\"C:\\Users\\Palash Ashok Bhosale\\Jupy\\Projects\\Bot_NLP\\pdf\\Framework of Roles, Activities and Competencies\"\n",
    "\n",
    "loader = NotionDirectoryLoader(path)\n",
    "docs = loader.load()\n",
    "# md_file=docs[0].page_content\n",
    "print(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7494b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_langchain_chunking(docs_path, splitters, chunk_size, chunk_overlap, drop_collection=True):\n",
    "\n",
    "\n",
    "    path=docs_path\n",
    "    loader = NotionDirectoryLoader(path)\n",
    "    docs = loader.load()\n",
    "    md_file=docs[0].page_content\n",
    "\n",
    "\n",
    "    # Let's create groups based on the section headers in our page\n",
    "    markdown_splitter = MarkdownHeaderTextSplitter(headers_to_split_on=splitters)\n",
    "    md_header_splits = markdown_splitter.split_text(md_file)\n",
    "\n",
    "\n",
    "    # Define our text splitter\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "    all_splits = text_splitter.split_documents(md_header_splits)\n",
    "\n",
    "\n",
    "    test_collection_name = f\"EngineeringNotionDoc_{chunk_size}_{chunk_overlap}\"\n",
    "\n",
    "\n",
    "    vectordb = Milvus.from_documents(documents=all_splits,\n",
    "        embedding=OpenAIEmbeddings(),\n",
    "        connection_args={\"uri\": zilliz_uri,\n",
    "            \"token\": zilliz_token},\n",
    "        collection_name=test_collection_name)\n",
    "\n",
    "\n",
    "    metadata_fields_info = [\n",
    "        AttributeInfo(\n",
    "            name=\"Section\",\n",
    "            description=\"Part of the document that the text comes from\",\n",
    "            type=\"string or list[string]\"\n",
    "        ),\n",
    "    ]\n",
    "    document_content_description = \"Major sections of the document\"\n",
    "\n",
    "\n",
    "    llm = OpenAI(temperature=0)\n",
    "    retriever = SelfQueryRetriever.from_llm(llm, vectordb, document_content_description, metadata_fields_info, verbose=True)\n",
    "\n",
    "\n",
    "    res = retriever.get_relevant_documents(\"What makes a distinguished engineer?\")\n",
    "    print(f\"\"\"Responses from chunking strategy:\n",
    "        {chunk_size}, {chunk_overlap}\"\"\")\n",
    "    for doc in res:\n",
    "        print(doc)\n",
    "\n",
    "\n",
    "    # this is just for rough cleanup, we can improve this# lots of user considerations to understand for real experimentation use cases thoughif drop_collection:\n",
    "        connections.connect(uri=zilliz_uri, token=zilliz_token)\n",
    "        utility.drop_collection(test_collection_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fa41e4e3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'headers_to_split_on' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mPalash Ashok Bhosale\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mJupy\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mProjects\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mBot_NLP\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mpdf\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mFramework of Roles, Activities and Competencies\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m test \u001b[38;5;129;01min\u001b[39;00m chunking_tests:\n\u001b[1;32m----> 4\u001b[0m     test_langchain_chunking(path, \u001b[43mheaders_to_split_on\u001b[49m, test[\u001b[38;5;241m0\u001b[39m], test[\u001b[38;5;241m1\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'headers_to_split_on' is not defined"
     ]
    }
   ],
   "source": [
    "chunking_tests = [(32, 4), (64, 8), (128, 16), (256, 32), (512, 64)]\n",
    "path=r\"C:\\Users\\Palash Ashok Bhosale\\Jupy\\Projects\\Bot_NLP\\pdf\\Framework of Roles, Activities and Competencies\"\n",
    "for test in chunking_tests:\n",
    "    test_langchain_chunking(path, headers_to_split_on, test[0], test[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "be4cb794",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pymilvus\n",
    "# pip install langchain\n",
    "# pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556f9fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "from langchain.text_splitter import MarkdownHeaderTextSplitter, RecursiveCharacterTextSplitter, CharacterTextSplitter\n",
    "from langchain.vectorstores import Milvus\n",
    "\n",
    "from pymilvus import CollectionSchema, FieldSchema, DataType, connections, utility, Collection\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "import PyPDF2\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a8b6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your Milvus server host and port\n",
    "MILVUS_HOST = \"localhost\"\n",
    "MILVUS_PORT = \"19530\"\n",
    "\n",
    "# Connect to Milvus\n",
    "connections.connect(host=MILVUS_HOST, port=MILVUS_PORT)\n",
    "print('Connected to Milvus!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3bcf7444",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[93m[__internal_register] retry:4, cost: 0.27s, reason: <_InactiveRpcError: StatusCode.UNAVAILABLE, failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:19530: connection attempt timed out before receiving SETTINGS frame>\u001b[0m\n",
      "\u001b[93m[__internal_register] retry:5, cost: 0.81s, reason: <_InactiveRpcError: StatusCode.UNAVAILABLE, failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:19530: connection attempt timed out before receiving SETTINGS frame>\u001b[0m\n",
      "\u001b[93m[__internal_register] retry:6, cost: 2.43s, reason: <_InactiveRpcError: StatusCode.UNAVAILABLE, failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:19530: connection attempt timed out before receiving SETTINGS frame>\u001b[0m\n",
      "\u001b[93m[__internal_register] retry:7, cost: 3.00s, reason: <_InactiveRpcError: StatusCode.UNAVAILABLE, failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:19530: connection attempt timed out before receiving SETTINGS frame>\u001b[0m\n",
      "\u001b[93m[__internal_register] retry:8, cost: 3.00s, reason: <_InactiveRpcError: StatusCode.UNAVAILABLE, failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:19530: connection attempt timed out before receiving SETTINGS frame>\u001b[0m\n",
      "\u001b[93m[__internal_register] retry:9, cost: 3.00s, reason: <_InactiveRpcError: StatusCode.UNAVAILABLE, failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:19530: connection attempt timed out before receiving SETTINGS frame>\u001b[0m\n",
      "\u001b[93m[__internal_register] retry:10, cost: 3.00s, reason: <_InactiveRpcError: StatusCode.UNAVAILABLE, failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:19530: connection attempt timed out before receiving SETTINGS frame>\u001b[0m\n",
      "\u001b[93m[__internal_register] retry:11, cost: 3.00s, reason: <_InactiveRpcError: StatusCode.UNAVAILABLE, failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:19530: connection attempt timed out before receiving SETTINGS frame>\u001b[0m\n",
      "\u001b[93m[__internal_register] retry:12, cost: 3.00s, reason: <_InactiveRpcError: StatusCode.UNAVAILABLE, failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:19530: connection attempt timed out before receiving SETTINGS frame>\u001b[0m\n",
      "\u001b[93m[__internal_register] retry:13, cost: 3.00s, reason: <_InactiveRpcError: StatusCode.UNAVAILABLE, failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:19530: connection attempt timed out before receiving SETTINGS frame>\u001b[0m\n",
      "\u001b[93m[__internal_register] retry:14, cost: 3.00s, reason: <_InactiveRpcError: StatusCode.UNAVAILABLE, failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:19530: connection attempt timed out before receiving SETTINGS frame>\u001b[0m\n",
      "\u001b[93m[__internal_register] retry:15, cost: 3.00s, reason: <_InactiveRpcError: StatusCode.UNAVAILABLE, failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:19530: connection attempt timed out before receiving SETTINGS frame>\u001b[0m\n",
      "\u001b[93m[__internal_register] retry:16, cost: 3.00s, reason: <_InactiveRpcError: StatusCode.UNAVAILABLE, failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:19530: connection attempt timed out before receiving SETTINGS frame>\u001b[0m\n",
      "\u001b[93m[__internal_register] retry:17, cost: 3.00s, reason: <_InactiveRpcError: StatusCode.UNAVAILABLE, failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:19530: connection attempt timed out before receiving SETTINGS frame>\u001b[0m\n",
      "\u001b[93m[__internal_register] retry:18, cost: 3.00s, reason: <_InactiveRpcError: StatusCode.UNAVAILABLE, failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:19530: connection attempt timed out before receiving SETTINGS frame>\u001b[0m\n",
      "\u001b[93m[__internal_register] retry:19, cost: 3.00s, reason: <_InactiveRpcError: StatusCode.UNAVAILABLE, failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:19530: connection attempt timed out before receiving SETTINGS frame>\u001b[0m\n",
      "\u001b[93m[__internal_register] retry:20, cost: 3.00s, reason: <_InactiveRpcError: StatusCode.UNAVAILABLE, failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:19530: connection attempt timed out before receiving SETTINGS frame>\u001b[0m\n",
      "\u001b[93m[__internal_register] retry:21, cost: 3.00s, reason: <_InactiveRpcError: StatusCode.UNAVAILABLE, failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:19530: connection attempt timed out before receiving SETTINGS frame>\u001b[0m\n",
      "\u001b[93m[__internal_register] retry:22, cost: 3.00s, reason: <_InactiveRpcError: StatusCode.UNAVAILABLE, failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:19530: connection attempt timed out before receiving SETTINGS frame>\u001b[0m\n",
      "\u001b[93m[__internal_register] retry:23, cost: 3.00s, reason: <_InactiveRpcError: StatusCode.UNAVAILABLE, failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:19530: connection attempt timed out before receiving SETTINGS frame>\u001b[0m\n",
      "\u001b[93m[__internal_register] retry:24, cost: 3.00s, reason: <_InactiveRpcError: StatusCode.UNAVAILABLE, failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:19530: connection attempt timed out before receiving SETTINGS frame>\u001b[0m\n",
      "\u001b[93m[__internal_register] retry:25, cost: 3.00s, reason: <_InactiveRpcError: StatusCode.UNAVAILABLE, failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:19530: connection attempt timed out before receiving SETTINGS frame>\u001b[0m\n",
      "\u001b[93m[__internal_register] retry:26, cost: 3.00s, reason: <_InactiveRpcError: StatusCode.UNAVAILABLE, failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:19530: connection attempt timed out before receiving SETTINGS frame>\u001b[0m\n",
      "\u001b[93m[__internal_register] retry:27, cost: 3.00s, reason: <_InactiveRpcError: StatusCode.UNAVAILABLE, failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:19530: connection attempt timed out before receiving SETTINGS frame>\u001b[0m\n",
      "\u001b[93m[__internal_register] retry:28, cost: 3.00s, reason: <_InactiveRpcError: StatusCode.UNAVAILABLE, failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:19530: connection attempt timed out before receiving SETTINGS frame>\u001b[0m\n",
      "\u001b[93m[__internal_register] retry:29, cost: 3.00s, reason: <_InactiveRpcError: StatusCode.UNAVAILABLE, failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:19530: connection attempt timed out before receiving SETTINGS frame>\u001b[0m\n",
      "\u001b[93m[__internal_register] retry:30, cost: 3.00s, reason: <_InactiveRpcError: StatusCode.UNAVAILABLE, failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:19530: connection attempt timed out before receiving SETTINGS frame>\u001b[0m\n",
      "\u001b[93m[__internal_register] retry:31, cost: 3.00s, reason: <_InactiveRpcError: StatusCode.UNAVAILABLE, failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:19530: connection attempt timed out before receiving SETTINGS frame>\u001b[0m\n",
      "\u001b[93m[__internal_register] retry:32, cost: 3.00s, reason: <_InactiveRpcError: StatusCode.UNAVAILABLE, failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:19530: connection attempt timed out before receiving SETTINGS frame>\u001b[0m\n",
      "\u001b[93m[__internal_register] retry:33, cost: 3.00s, reason: <_InactiveRpcError: StatusCode.UNAVAILABLE, failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:19530: connection attempt timed out before receiving SETTINGS frame>\u001b[0m\n",
      "\u001b[93m[__internal_register] retry:34, cost: 3.00s, reason: <_InactiveRpcError: StatusCode.UNAVAILABLE, failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:19530: connection attempt timed out before receiving SETTINGS frame>\u001b[0m\n",
      "\u001b[93m[__internal_register] retry:35, cost: 3.00s, reason: <_InactiveRpcError: StatusCode.UNAVAILABLE, failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:19530: connection attempt timed out before receiving SETTINGS frame>\u001b[0m\n",
      "\u001b[93m[__internal_register] retry:36, cost: 3.00s, reason: <_InactiveRpcError: StatusCode.UNAVAILABLE, failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:19530: connection attempt timed out before receiving SETTINGS frame>\u001b[0m\n",
      "\u001b[93m[__internal_register] retry:37, cost: 3.00s, reason: <_InactiveRpcError: StatusCode.UNAVAILABLE, failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:19530: connection attempt timed out before receiving SETTINGS frame>\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[93m[__internal_register] retry:38, cost: 3.00s, reason: <_InactiveRpcError: StatusCode.UNAVAILABLE, failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:19530: connection attempt timed out before receiving SETTINGS frame>\u001b[0m\n",
      "\u001b[93m[__internal_register] retry:39, cost: 3.00s, reason: <_InactiveRpcError: StatusCode.UNAVAILABLE, failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:19530: connection attempt timed out before receiving SETTINGS frame>\u001b[0m\n",
      "\u001b[93m[__internal_register] retry:40, cost: 3.00s, reason: <_InactiveRpcError: StatusCode.UNAVAILABLE, failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:19530: connection attempt timed out before receiving SETTINGS frame>\u001b[0m\n",
      "\u001b[93m[__internal_register] retry:41, cost: 3.00s, reason: <_InactiveRpcError: StatusCode.UNAVAILABLE, failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:19530: connection attempt timed out before receiving SETTINGS frame>\u001b[0m\n",
      "\u001b[93m[__internal_register] retry:42, cost: 3.00s, reason: <_InactiveRpcError: StatusCode.UNAVAILABLE, failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:19530: connection attempt timed out before receiving SETTINGS frame>\u001b[0m\n",
      "\u001b[93m[__internal_register] retry:43, cost: 3.00s, reason: <_InactiveRpcError: StatusCode.UNAVAILABLE, failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:19530: connection attempt timed out before receiving SETTINGS frame>\u001b[0m\n",
      "\u001b[93m[__internal_register] retry:44, cost: 3.00s, reason: <_InactiveRpcError: StatusCode.UNAVAILABLE, failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:19530: connection attempt timed out before receiving SETTINGS frame>\u001b[0m\n",
      "\u001b[93m[__internal_register] retry:45, cost: 3.00s, reason: <_InactiveRpcError: StatusCode.UNAVAILABLE, failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:19530: connection attempt timed out before receiving SETTINGS frame>\u001b[0m\n",
      "\u001b[93m[__internal_register] retry:46, cost: 3.00s, reason: <_InactiveRpcError: StatusCode.UNAVAILABLE, failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:19530: connection attempt timed out before receiving SETTINGS frame>\u001b[0m\n",
      "\u001b[93m[__internal_register] retry:47, cost: 3.00s, reason: <_InactiveRpcError: StatusCode.UNAVAILABLE, failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:19530: connection attempt timed out before receiving SETTINGS frame>\u001b[0m\n",
      "\u001b[93m[__internal_register] retry:48, cost: 3.00s, reason: <_InactiveRpcError: StatusCode.UNAVAILABLE, failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:19530: connection attempt timed out before receiving SETTINGS frame>\u001b[0m\n",
      "\u001b[93m[__internal_register] retry:49, cost: 3.00s, reason: <_InactiveRpcError: StatusCode.UNAVAILABLE, failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:19530: connection attempt timed out before receiving SETTINGS frame>\u001b[0m\n",
      "\u001b[93m[__internal_register] retry:50, cost: 3.00s, reason: <_InactiveRpcError: StatusCode.UNAVAILABLE, failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:19530: connection attempt timed out before receiving SETTINGS frame>\u001b[0m\n",
      "\u001b[93m[__internal_register] retry:51, cost: 3.00s, reason: <_InactiveRpcError: StatusCode.UNAVAILABLE, failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:19530: connection attempt timed out before receiving SETTINGS frame>\u001b[0m\n",
      "\u001b[93m[__internal_register] retry:52, cost: 3.00s, reason: <_InactiveRpcError: StatusCode.UNAVAILABLE, failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:19530: connection attempt timed out before receiving SETTINGS frame>\u001b[0m\n",
      "\u001b[93m[__internal_register] retry:53, cost: 3.00s, reason: <_InactiveRpcError: StatusCode.UNAVAILABLE, failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:19530: connection attempt timed out before receiving SETTINGS frame>\u001b[0m\n",
      "\u001b[93m[__internal_register] retry:54, cost: 3.00s, reason: <_InactiveRpcError: StatusCode.UNAVAILABLE, failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:19530: connection attempt timed out before receiving SETTINGS frame>\u001b[0m\n",
      "\u001b[93m[__internal_register] retry:55, cost: 3.00s, reason: <_InactiveRpcError: StatusCode.UNAVAILABLE, failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:19530: connection attempt timed out before receiving SETTINGS frame>\u001b[0m\n",
      "\u001b[93m[__internal_register] retry:56, cost: 3.00s, reason: <_InactiveRpcError: StatusCode.UNAVAILABLE, failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:19530: connection attempt timed out before receiving SETTINGS frame>\u001b[0m\n",
      "\u001b[93m[__internal_register] retry:57, cost: 3.00s, reason: <_InactiveRpcError: StatusCode.UNAVAILABLE, failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:19530: connection attempt timed out before receiving SETTINGS frame>\u001b[0m\n",
      "\u001b[93m[__internal_register] retry:58, cost: 3.00s, reason: <_InactiveRpcError: StatusCode.UNAVAILABLE, failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:19530: connection attempt timed out before receiving SETTINGS frame>\u001b[0m\n",
      "\u001b[93m[__internal_register] retry:59, cost: 3.00s, reason: <_InactiveRpcError: StatusCode.UNAVAILABLE, failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:19530: connection attempt timed out before receiving SETTINGS frame>\u001b[0m\n",
      "\u001b[93m[__internal_register] retry:60, cost: 3.00s, reason: <_InactiveRpcError: StatusCode.UNAVAILABLE, failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:19530: connection attempt timed out before receiving SETTINGS frame>\u001b[0m\n",
      "\u001b[93m[__internal_register] retry:61, cost: 3.00s, reason: <_InactiveRpcError: StatusCode.UNAVAILABLE, failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:19530: connection attempt timed out before receiving SETTINGS frame>\u001b[0m\n",
      "\u001b[93m[__internal_register] retry:62, cost: 3.00s, reason: <_InactiveRpcError: StatusCode.UNAVAILABLE, failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:19530: connection attempt timed out before receiving SETTINGS frame>\u001b[0m\n",
      "\u001b[93m[__internal_register] retry:63, cost: 3.00s, reason: <_InactiveRpcError: StatusCode.UNAVAILABLE, failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:19530: connection attempt timed out before receiving SETTINGS frame>\u001b[0m\n",
      "\u001b[93m[__internal_register] retry:64, cost: 3.00s, reason: <_InactiveRpcError: StatusCode.UNAVAILABLE, failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:19530: connection attempt timed out before receiving SETTINGS frame>\u001b[0m\n",
      "\u001b[93m[__internal_register] retry:65, cost: 3.00s, reason: <_InactiveRpcError: StatusCode.UNAVAILABLE, failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:19530: connection attempt timed out before receiving SETTINGS frame>\u001b[0m\n",
      "\u001b[93m[__internal_register] retry:66, cost: 3.00s, reason: <_InactiveRpcError: StatusCode.UNAVAILABLE, failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:19530: connection attempt timed out before receiving SETTINGS frame>\u001b[0m\n",
      "\u001b[93m[__internal_register] retry:67, cost: 3.00s, reason: <_InactiveRpcError: StatusCode.UNAVAILABLE, failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:19530: connection attempt timed out before receiving SETTINGS frame>\u001b[0m\n",
      "\u001b[93m[__internal_register] retry:68, cost: 3.00s, reason: <_InactiveRpcError: StatusCode.UNAVAILABLE, failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:19530: connection attempt timed out before receiving SETTINGS frame>\u001b[0m\n",
      "\u001b[93m[__internal_register] retry:69, cost: 3.00s, reason: <_InactiveRpcError: StatusCode.UNAVAILABLE, failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:19530: connection attempt timed out before receiving SETTINGS frame>\u001b[0m\n",
      "\u001b[93m[__internal_register] retry:70, cost: 3.00s, reason: <_InactiveRpcError: StatusCode.UNAVAILABLE, failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:19530: connection attempt timed out before receiving SETTINGS frame>\u001b[0m\n",
      "\u001b[93m[__internal_register] retry:71, cost: 3.00s, reason: <_InactiveRpcError: StatusCode.UNAVAILABLE, failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:19530: connection attempt timed out before receiving SETTINGS frame>\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[93m[__internal_register] retry:72, cost: 3.00s, reason: <_InactiveRpcError: StatusCode.UNAVAILABLE, failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:19530: connection attempt timed out before receiving SETTINGS frame>\u001b[0m\n",
      "\u001b[93m[__internal_register] retry:73, cost: 3.00s, reason: <_InactiveRpcError: StatusCode.UNAVAILABLE, failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:19530: connection attempt timed out before receiving SETTINGS frame>\u001b[0m\n",
      "\u001b[93m[__internal_register] retry:74, cost: 3.00s, reason: <_InactiveRpcError: StatusCode.UNAVAILABLE, failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:19530: connection attempt timed out before receiving SETTINGS frame>\u001b[0m\n",
      "\u001b[93m[__internal_register] retry:75, cost: 3.00s, reason: <_InactiveRpcError: StatusCode.UNAVAILABLE, failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:19530: connection attempt timed out before receiving SETTINGS frame>\u001b[0m\n",
      "RPC error: [__internal_register], <MilvusException: (code=<bound method _InactiveRpcError.code of <_InactiveRpcError of RPC that terminated with:\n",
      "\tstatus = StatusCode.UNAVAILABLE\n",
      "\tdetails = \"failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:19530: connection attempt timed out before receiving SETTINGS frame\"\n",
      "\tdebug_error_string = \"UNKNOWN:failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:19530: connection attempt timed out before receiving SETTINGS frame {grpc_status:14, created_time:\"2023-11-08T10:40:17.8733398+00:00\"}\"\n",
      ">>, message=Retry run out of 75 retry times, message=failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:19530: connection attempt timed out before receiving SETTINGS frame)>, <Time:{'RPC start': '2023-11-08 16:05:32.983619', 'RPC error': '2023-11-08 16:10:17.900130'}>\n"
     ]
    },
    {
     "ename": "MilvusException",
     "evalue": "<MilvusException: (code=<bound method _InactiveRpcError.code of <_InactiveRpcError of RPC that terminated with:\n\tstatus = StatusCode.UNAVAILABLE\n\tdetails = \"failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:19530: connection attempt timed out before receiving SETTINGS frame\"\n\tdebug_error_string = \"UNKNOWN:failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:19530: connection attempt timed out before receiving SETTINGS frame {grpc_status:14, created_time:\"2023-11-08T10:40:17.8733398+00:00\"}\"\n>>, message=Retry run out of 75 retry times, message=failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:19530: connection attempt timed out before receiving SETTINGS frame)>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMilvusException\u001b[0m                           Traceback (most recent call last)",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "Cell \u001b[1;32mIn[82], line 15\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Connect to Milvus\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m \u001b[43mconnections\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhost\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMILVUS_HOST\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mport\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMILVUS_PORT\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mConnected to Milvus!\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pymilvus\\orm\\connections.py:354\u001b[0m, in \u001b[0;36mConnections.connect\u001b[1;34m(self, alias, user, password, db_name, token, **kwargs)\u001b[0m\n\u001b[0;32m    352\u001b[0m         kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msecure\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 354\u001b[0m \u001b[43mconnect_milvus\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpassword\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdb_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdb_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pymilvus\\orm\\connections.py:302\u001b[0m, in \u001b[0;36mConnections.connect.<locals>.connect_milvus\u001b[1;34m(**kwargs)\u001b[0m\n\u001b[0;32m    300\u001b[0m timeout \u001b[38;5;241m=\u001b[39m t \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, (\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mfloat\u001b[39m)) \u001b[38;5;28;01melse\u001b[39;00m Config\u001b[38;5;241m.\u001b[39mMILVUS_CONN_TIMEOUT\n\u001b[1;32m--> 302\u001b[0m \u001b[43mgh\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait_for_channel_ready\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    303\u001b[0m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassword\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pymilvus\\client\\grpc_handler.py:139\u001b[0m, in \u001b[0;36mGrpcHandler._wait_for_channel_ready\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 139\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pymilvus\\client\\grpc_handler.py:132\u001b[0m, in \u001b[0;36mGrpcHandler._wait_for_channel_ready\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    131\u001b[0m     grpc\u001b[38;5;241m.\u001b[39mchannel_ready_future(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_channel)\u001b[38;5;241m.\u001b[39mresult(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m--> 132\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setup_identifier_interceptor\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_user\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mFutureTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pymilvus\\client\\grpc_handler.py:249\u001b[0m, in \u001b[0;36mGrpcHandler._setup_identifier_interceptor\u001b[1;34m(self, user)\u001b[0m\n\u001b[0;32m    248\u001b[0m host \u001b[38;5;241m=\u001b[39m socket\u001b[38;5;241m.\u001b[39mgethostname()\n\u001b[1;32m--> 249\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_identifier \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__internal_register\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhost\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_identifier_interceptor \u001b[38;5;241m=\u001b[39m interceptor\u001b[38;5;241m.\u001b[39mheader_adder_interceptor(\n\u001b[0;32m    251\u001b[0m     [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124midentifier\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_identifier)]\n\u001b[0;32m    252\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pymilvus\\decorators.py:127\u001b[0m, in \u001b[0;36mhandler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m MilvusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 127\u001b[0m     record_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRPC error\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow())\n\u001b[0;32m    128\u001b[0m     LOGGER\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRPC error: [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00minner_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m], \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, <Time:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrecord_dict\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m>\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pymilvus\\decorators.py:123\u001b[0m, in \u001b[0;36mhandler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    122\u001b[0m record_dict \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m--> 123\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     record_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRPC start\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow())\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pymilvus\\decorators.py:162\u001b[0m, in \u001b[0;36mhandler\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    161\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_onetime_loglevel(level)\n\u001b[1;32m--> 162\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m req_id:\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_onetime_request_id(req_id)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pymilvus\\decorators.py:81\u001b[0m, in \u001b[0;36mretry_on_rpc_failure.<locals>.wrapper.<locals>.handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout(start_time):\n\u001b[1;32m---> 81\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MilvusException(e\u001b[38;5;241m.\u001b[39mcode, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mto_msg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, message=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;241m.\u001b[39mdetails()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m counter \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m3\u001b[39m:\n",
      "\u001b[1;31mMilvusException\u001b[0m: <MilvusException: (code=<bound method _InactiveRpcError.code of <_InactiveRpcError of RPC that terminated with:\n\tstatus = StatusCode.UNAVAILABLE\n\tdetails = \"failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:19530: connection attempt timed out before receiving SETTINGS frame\"\n\tdebug_error_string = \"UNKNOWN:failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:19530: connection attempt timed out before receiving SETTINGS frame {grpc_status:14, created_time:\"2023-11-08T10:40:17.8733398+00:00\"}\"\n>>, message=Retry run out of 75 retry times, message=failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:19530: connection attempt timed out before receiving SETTINGS frame)>",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mMilvusException\u001b[0m                           Traceback (most recent call last)",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "Cell \u001b[1;32mIn[82], line 15\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Connect to Milvus\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m \u001b[43mconnections\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhost\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMILVUS_HOST\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mport\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMILVUS_PORT\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mConnected to Milvus!\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pymilvus\\orm\\connections.py:354\u001b[0m, in \u001b[0;36mConnections.connect\u001b[1;34m(self, alias, user, password, db_name, token, **kwargs)\u001b[0m\n\u001b[0;32m    352\u001b[0m         kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msecure\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 354\u001b[0m \u001b[43mconnect_milvus\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpassword\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdb_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdb_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pymilvus\\orm\\connections.py:302\u001b[0m, in \u001b[0;36mConnections.connect.<locals>.connect_milvus\u001b[1;34m(**kwargs)\u001b[0m\n\u001b[0;32m    300\u001b[0m timeout \u001b[38;5;241m=\u001b[39m t \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, (\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mfloat\u001b[39m)) \u001b[38;5;28;01melse\u001b[39;00m Config\u001b[38;5;241m.\u001b[39mMILVUS_CONN_TIMEOUT\n\u001b[1;32m--> 302\u001b[0m \u001b[43mgh\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait_for_channel_ready\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    303\u001b[0m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassword\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pymilvus\\client\\grpc_handler.py:139\u001b[0m, in \u001b[0;36mGrpcHandler._wait_for_channel_ready\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 139\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pymilvus\\client\\grpc_handler.py:132\u001b[0m, in \u001b[0;36mGrpcHandler._wait_for_channel_ready\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    131\u001b[0m     grpc\u001b[38;5;241m.\u001b[39mchannel_ready_future(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_channel)\u001b[38;5;241m.\u001b[39mresult(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m--> 132\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setup_identifier_interceptor\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_user\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mFutureTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pymilvus\\client\\grpc_handler.py:249\u001b[0m, in \u001b[0;36mGrpcHandler._setup_identifier_interceptor\u001b[1;34m(self, user)\u001b[0m\n\u001b[0;32m    248\u001b[0m host \u001b[38;5;241m=\u001b[39m socket\u001b[38;5;241m.\u001b[39mgethostname()\n\u001b[1;32m--> 249\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_identifier \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__internal_register\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhost\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_identifier_interceptor \u001b[38;5;241m=\u001b[39m interceptor\u001b[38;5;241m.\u001b[39mheader_adder_interceptor(\n\u001b[0;32m    251\u001b[0m     [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124midentifier\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_identifier)]\n\u001b[0;32m    252\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pymilvus\\decorators.py:127\u001b[0m, in \u001b[0;36mhandler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m MilvusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 127\u001b[0m     record_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRPC error\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow())\n\u001b[0;32m    128\u001b[0m     LOGGER\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRPC error: [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00minner_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m], \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, <Time:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrecord_dict\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m>\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pymilvus\\decorators.py:123\u001b[0m, in \u001b[0;36mhandler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    122\u001b[0m record_dict \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m--> 123\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     record_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRPC start\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow())\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pymilvus\\decorators.py:162\u001b[0m, in \u001b[0;36mhandler\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    161\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_onetime_loglevel(level)\n\u001b[1;32m--> 162\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m req_id:\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_onetime_request_id(req_id)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pymilvus\\decorators.py:81\u001b[0m, in \u001b[0;36mretry_on_rpc_failure.<locals>.wrapper.<locals>.handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout(start_time):\n\u001b[1;32m---> 81\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MilvusException(e\u001b[38;5;241m.\u001b[39mcode, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mto_msg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, message=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;241m.\u001b[39mdetails()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m counter \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m3\u001b[39m:\n",
      "\u001b[1;31mMilvusException\u001b[0m: <MilvusException: (code=<bound method _InactiveRpcError.code of <_InactiveRpcError of RPC that terminated with:\n\tstatus = StatusCode.UNAVAILABLE\n\tdetails = \"failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:19530: connection attempt timed out before receiving SETTINGS frame\"\n\tdebug_error_string = \"UNKNOWN:failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:19530: connection attempt timed out before receiving SETTINGS frame {grpc_status:14, created_time:\"2023-11-08T10:40:17.8733398+00:00\"}\"\n>>, message=Retry run out of 75 retry times, message=failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:19530: connection attempt timed out before receiving SETTINGS frame)>",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mMilvusException\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[82], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m MILVUS_PORT \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m19530\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Connect to Milvus\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m \u001b[43mconnections\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhost\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMILVUS_HOST\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mport\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMILVUS_PORT\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mConnected to Milvus!\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Define the schema for the collection\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pymilvus\\orm\\connections.py:354\u001b[0m, in \u001b[0;36mConnections.connect\u001b[1;34m(self, alias, user, password, db_name, token, **kwargs)\u001b[0m\n\u001b[0;32m    351\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m parsed_uri\u001b[38;5;241m.\u001b[39mscheme \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    352\u001b[0m             kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msecure\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 354\u001b[0m     \u001b[43mconnect_milvus\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpassword\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdb_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdb_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    355\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    357\u001b[0m \u001b[38;5;66;03m# 2nd Priority, connection configs from env\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pymilvus\\orm\\connections.py:302\u001b[0m, in \u001b[0;36mConnections.connect.<locals>.connect_milvus\u001b[1;34m(**kwargs)\u001b[0m\n\u001b[0;32m    299\u001b[0m t \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    300\u001b[0m timeout \u001b[38;5;241m=\u001b[39m t \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, (\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mfloat\u001b[39m)) \u001b[38;5;28;01melse\u001b[39;00m Config\u001b[38;5;241m.\u001b[39mMILVUS_CONN_TIMEOUT\n\u001b[1;32m--> 302\u001b[0m \u001b[43mgh\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait_for_channel_ready\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    303\u001b[0m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassword\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    304\u001b[0m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pymilvus\\client\\grpc_handler.py:139\u001b[0m, in \u001b[0;36mGrpcHandler._wait_for_channel_ready\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    134\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MilvusException(\n\u001b[0;32m    135\u001b[0m         code\u001b[38;5;241m=\u001b[39mStatus\u001b[38;5;241m.\u001b[39mCONNECT_FAILED,\n\u001b[0;32m    136\u001b[0m         message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFail connecting to server on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_address\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Timeout\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    137\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 139\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pymilvus\\client\\grpc_handler.py:132\u001b[0m, in \u001b[0;36mGrpcHandler._wait_for_channel_ready\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    131\u001b[0m     grpc\u001b[38;5;241m.\u001b[39mchannel_ready_future(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_channel)\u001b[38;5;241m.\u001b[39mresult(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m--> 132\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setup_identifier_interceptor\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_user\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mFutureTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    134\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MilvusException(\n\u001b[0;32m    135\u001b[0m         code\u001b[38;5;241m=\u001b[39mStatus\u001b[38;5;241m.\u001b[39mCONNECT_FAILED,\n\u001b[0;32m    136\u001b[0m         message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFail connecting to server on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_address\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Timeout\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    137\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pymilvus\\client\\grpc_handler.py:249\u001b[0m, in \u001b[0;36mGrpcHandler._setup_identifier_interceptor\u001b[1;34m(self, user)\u001b[0m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_setup_identifier_interceptor\u001b[39m(\u001b[38;5;28mself\u001b[39m, user: \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    248\u001b[0m     host \u001b[38;5;241m=\u001b[39m socket\u001b[38;5;241m.\u001b[39mgethostname()\n\u001b[1;32m--> 249\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_identifier \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__internal_register\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhost\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    250\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_identifier_interceptor \u001b[38;5;241m=\u001b[39m interceptor\u001b[38;5;241m.\u001b[39mheader_adder_interceptor(\n\u001b[0;32m    251\u001b[0m         [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124midentifier\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_identifier)]\n\u001b[0;32m    252\u001b[0m     )\n\u001b[0;32m    253\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_channel \u001b[38;5;241m=\u001b[39m grpc\u001b[38;5;241m.\u001b[39mintercept_channel(\n\u001b[0;32m    254\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_channel, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_identifier_interceptor\n\u001b[0;32m    255\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pymilvus\\decorators.py:127\u001b[0m, in \u001b[0;36mhandler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m MilvusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 127\u001b[0m     record_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRPC error\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow())\n\u001b[0;32m    128\u001b[0m     LOGGER\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRPC error: [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00minner_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m], \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, <Time:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrecord_dict\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m>\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    129\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pymilvus\\decorators.py:123\u001b[0m, in \u001b[0;36mhandler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    121\u001b[0m     inner_name \u001b[38;5;241m=\u001b[39m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n\u001b[0;32m    122\u001b[0m record_dict \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m--> 123\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     record_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRPC start\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow())\n\u001b[0;32m    125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pymilvus\\decorators.py:162\u001b[0m, in \u001b[0;36mhandler\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m level:\n\u001b[0;32m    161\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_onetime_loglevel(level)\n\u001b[1;32m--> 162\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m req_id:\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_onetime_request_id(req_id)\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pymilvus\\decorators.py:81\u001b[0m, in \u001b[0;36mretry_on_rpc_failure.<locals>.wrapper.<locals>.handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout(start_time):\n\u001b[1;32m---> 81\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MilvusException(e\u001b[38;5;241m.\u001b[39mcode, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mto_msg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, message=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;241m.\u001b[39mdetails()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m counter \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[0;32m     84\u001b[0m     retry_msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     85\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] retry:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcounter\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, cost: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mback_off\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124ms, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     86\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreason: <\u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;241m.\u001b[39mcode()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;241m.\u001b[39mdetails()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m>\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     87\u001b[0m     )\n",
      "\u001b[1;31mMilvusException\u001b[0m: <MilvusException: (code=<bound method _InactiveRpcError.code of <_InactiveRpcError of RPC that terminated with:\n\tstatus = StatusCode.UNAVAILABLE\n\tdetails = \"failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:19530: connection attempt timed out before receiving SETTINGS frame\"\n\tdebug_error_string = \"UNKNOWN:failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:19530: connection attempt timed out before receiving SETTINGS frame {grpc_status:14, created_time:\"2023-11-08T10:40:17.8733398+00:00\"}\"\n>>, message=Retry run out of 75 retry times, message=failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:19530: connection attempt timed out before receiving SETTINGS frame)>"
     ]
    }
   ],
   "source": [
    "# Define the schema for the collection\n",
    "document_id = FieldSchema(name='document_id', dtype=DataType.INT64, is_primary=True, auto_id=True)\n",
    "metadata = FieldSchema(name='metadata', dtype=DataType.VARCHAR, max_length=50000)\n",
    "metadata_page = FieldSchema(name='metadata_page', dtype=DataType.INT64)\n",
    "embeddings = FieldSchema(name='embeddings', dtype=DataType.FLOAT_VECTOR, dim=768)\n",
    "text = FieldSchema(name='text', dtype=DataType.VARCHAR, max_length=65535)\n",
    "\n",
    "schema = CollectionSchema(fields=[document_id, metadata, metadata_page, embeddings, text], enable_dynamic_field=True)\n",
    "\n",
    "# Create or access the collection\n",
    "collection_name = 'BirlaCarbonEmbeddings'\n",
    "if not utility.has_collection(collection_name):\n",
    "    collection = Collection(name=collection_name, schema=schema, using='default')\n",
    "    print('Collection created!')\n",
    "else:\n",
    "    collection = Collection(collection_name)\n",
    "    print('Collection already exists.')\n",
    "\n",
    "# Iterate through PDF files in the \"./docs\" directory\n",
    "document = []\n",
    "folder_path=r\"C:\\Users\\Palash Ashok Bhosale\\Jupy\\Projects\\Bot_NLP\\pdf\"\n",
    "for file in os.listdir(folder_path):\n",
    "    if file.endswith(\".pdf\"):\n",
    "        pdf_path = folder_path + file\n",
    "        loader = PyPDF2(pdf_path)\n",
    "        document.extend(loader.load())\n",
    "\n",
    "# Split the loaded documents into chunks\n",
    "document_splitter = CharacterTextSplitter(separator='\\n', chunk_size=500, chunk_overlap=100)\n",
    "document_chunks = document_splitter.split_documents(document)\n",
    "print(document_chunks)\n",
    "\n",
    "# Load the instructor model\n",
    "model = INSTRUCTOR(model_name_or_path=\"./ml_models/hkunlp_instructor-xl\")\n",
    "print('Model loaded!')\n",
    "\n",
    "# Process and insert data into Milvus\n",
    "metadata_list = []\n",
    "metadata_page_list = []\n",
    "embedding_list = []\n",
    "text_list = []\n",
    "for i in document_chunks:\n",
    "    text = i.page_content\n",
    "    metadata = i.metadata['source']\n",
    "    metadata_page = i.metadata['page']\n",
    "    text_list.append(text)\n",
    "    embeddings = model.encode(text)\n",
    "    embedding_list.append(embeddings)\n",
    "    metadata_list.append(metadata)\n",
    "    metadata_page_list.append(metadata_page)\n",
    "\n",
    "collection.insert([metadata_list, metadata_page_list, embedding_list, text_list])\n",
    "print('Data inserted into the collection.')\n",
    "\n",
    "# Create an index on the \"embeddings\" field\n",
    "index_params = {\n",
    "    'metric_type': 'L2',\n",
    "    'index_type': \"IVF_FLAT\",\n",
    "    'params': {\"nlist\": 2048}\n",
    "}\n",
    "collection.create_index(field_name=\"embeddings\", index_params=index_params)\n",
    "print('Index created.')\n",
    "\n",
    "# Load the collection\n",
    "collection.load()\n",
    "print('Collection loaded.')\n",
    "\n",
    "# Define a query and search for similar documents\n",
    "query = \"What is Fabrication of LIBs\"\n",
    "query_encode = model.encode(query)\n",
    "\n",
    "documents = collection.search(data=[query_encode], anns_field=\"embeddings\", param={\"metric\": \"L2\", \"offset\": 0},\n",
    "                             output_fields=[\"metadata\", \"metadata_page\", \"text\"], limit=10, consistency_level=\"Strong\")\n",
    "\n",
    "print(\"Similar documents:\")\n",
    "for doc in documents:\n",
    "    print(\"Metadata: \", doc.metadata)\n",
    "    print(\"Page: \", doc.metadata_page)\n",
    "    print(\"Text: \", doc.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "54adb193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "automation (as per MDOs \n",
      "agreed policy)    Leading others  \n",
      "   Consultation and \n",
      "communication \n",
      "building  \n",
      "   Taking accountability  \n",
      "   Innovative thinking  \n",
      "   Problem solving  Recruitment Workflow \n",
      "Modifications  Suggest changes in the \n",
      "workflow as per iGOT \n",
      "recommendations  Deep understanding of \n",
      "the FRAC process  Methods of project \n",
      "communication  Leading others  \n",
      "Draw up change note for HR \n",
      "head's approval  Usage of FRAC \n",
      "templates and \n",
      "methodologies    Organisational \n",
      "awareness  \n",
      "Identify assessment processes \n",
      "for adoption by MDOs \n",
      "recruitment  Assessment \n",
      "technologies and \n",
      "processes    Commitment to \n",
      "organisation  \n",
      "      Self-confidence  Project Contribution  Understand project strategy  MS project; primavera;\n"
     ]
    }
   ],
   "source": [
    "query = \"What is learn hub?\"\n",
    "query_encode = model.encode(query)\n",
    "# results = collection.search(query_embeddings, field_name, param=search_params, limit=9, expr=None)\n",
    "results=collection.search(data=[query_encode], anns_field=\"embeddings\", param={\"metric\": \"L2\", \"offset\": 0},\n",
    "                             output_fields=[\"metadata\", \"metadata_page\", \"text\"], limit=10, consistency_level=\"Strong\")\n",
    "# print(results)\n",
    "for result in results[0]:\n",
    "    sql = str(result.text) + \";\"\n",
    "    print(sql)\n",
    "    break\n",
    "#     if len(sql):\n",
    "#         similar_titles.append((rows[0][0], result.distance))\n",
    "#         print((sql, result.distance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2f8251a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "from langchain.text_splitter import MarkdownHeaderTextSplitter, RecursiveCharacterTextSplitter, CharacterTextSplitter\n",
    "from langchain.vectorstores import Milvus\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from pymilvus import CollectionSchema, FieldSchema, DataType, connections, utility, Collection\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import re\n",
    "import PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "17697e33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384\n"
     ]
    }
   ],
   "source": [
    "model= SentenceTransformer('paraphrase-MiniLM-L3-v2')\n",
    "embeddings = model.encode(\"sample text\")\n",
    "print(len(embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "05adeaad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Milvus!\n",
      "Collection created!\n"
     ]
    }
   ],
   "source": [
    "MILVUS_HOST = \"localhost\"\n",
    "MILVUS_PORT = \"19530\"\n",
    "\n",
    "connections.connect(host=MILVUS_HOST, port=MILVUS_PORT)\n",
    "print('Connected to Milvus!')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "document_id = FieldSchema(name='document_id', dtype=DataType.INT64, is_primary=True, auto_id=True)\n",
    "metadata = FieldSchema(name='metadata', dtype=DataType.VARCHAR, max_length=50000)\n",
    "metadata_page = FieldSchema(name='metadata_page', dtype=DataType.INT64)\n",
    "# embeddings = FieldSchema(name='embeddings', dtype=DataType.FLOAT_VECTOR, dim=384)\n",
    "embeddings = FieldSchema(name='embeddings', dtype=DataType.FLOAT_VECTOR, dim=384)  \n",
    "\n",
    "text = FieldSchema(name='text', dtype=DataType.VARCHAR, max_length=65535)\n",
    "\n",
    "schema = CollectionSchema(fields=[document_id, metadata, metadata_page, embeddings, text], enable_dynamic_field=True)\n",
    "\n",
    "\n",
    "\n",
    "class SimpleDocument:\n",
    "    def __init__(self, page_content, metadata=None):\n",
    "        self.page_content = page_content\n",
    "        self.metadata = {} if metadata is None else metadata\n",
    "\n",
    "collection_name = 'a1'\n",
    "if not utility.has_collection(collection_name):\n",
    "    collection = Collection(name=collection_name, schema=schema, using='default')\n",
    "    print('Collection created!')\n",
    "else:\n",
    "    collection = Collection(collection_name)\n",
    "    print('Collection already exists.')\n",
    "\n",
    "# Iterate through PDF files in the \"./docs\" directory\n",
    "# document = []\n",
    "# file_name = \"C://Users//Palash Ashok Bhosale//Jupy//Projects//Bot_NLP//pdf//Framework of Roles, Activities and Competencies.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d32ab9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "metadata_list = []\n",
    "metadata_page_list = []\n",
    "embedding_list = []\n",
    "text_list = []\n",
    "\n",
    "folder_path = r\"C:\\Users\\Palash Ashok Bhosale\\Jupy\\Projects\\Bot_NLP\\pdf\"   \n",
    "document = []\n",
    "for file_name in os.listdir(folder_path):\n",
    "    if file_name.endswith(\".pdf\"):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "\n",
    "        with open(file_path, 'rb') as pdf_file:\n",
    "            \n",
    "            pdf_reader = PyPDF2.PdfReader(pdf_file)\n",
    "            count=1\n",
    "            for page in range(0,len(pdf_reader.pages)):\n",
    "                text = pdf_reader.pages[page].extract_text()\n",
    "                \n",
    "                \n",
    "                    \n",
    "                \n",
    "                try:\n",
    "                    document_splitter = RecursiveCharacterTextSplitter(chunk_size=300, chunk_overlap=0, length_function=len)\n",
    "                    # print(document_splitter)\n",
    "                    document_chunks = document_splitter.split_documents([SimpleDocument(text)])\n",
    "                    \n",
    "\n",
    "                    for i, document_chunk in enumerate(document_chunks):\n",
    "\n",
    "                        document_chunk_text = re.sub(\" \\n\", \" \", document_chunk.page_content)\n",
    "                        paragraph=document_chunk_text\n",
    "                        \n",
    "                        # model = FCoref(device='cuda:0')\n",
    "                        # model = FCoref(device='cpu')\n",
    "                        # preds = model.predict(\n",
    "                        # texts=[paragraph]\n",
    "                        # )\n",
    "\n",
    "                        # preds[0].get_clusters(as_strings=False)\n",
    "                        # clusters=preds[0].get_clusters()\n",
    "\n",
    "\n",
    "                        # for cluster in clusters:\n",
    "                        #     for i in range (len(cluster)):\n",
    "\n",
    "                        #         paragraph=paragraph.replace(cluster[i-1], cluster[0], 1)\n",
    "\n",
    "\n",
    "                        text = paragraph\n",
    "                        metadata = f\"{file_name}_{count}_{i}\"\n",
    "                        metadata_page = i\n",
    "                        text_list.append(text)\n",
    "                        embeddings = model.encode(text)\n",
    "                        embedding_list.append(embeddings)\n",
    "                        metadata_list.append(metadata)\n",
    "                        metadata_page_list.append(metadata_page)\n",
    "                        # print(len(embeddings))\n",
    "                        \n",
    "\n",
    "                except:\n",
    "                    print(\"in except block\")\n",
    "\n",
    "                \n",
    "                    \n",
    "\n",
    "                    # collection.insert([metadata_list, metadata_page_list, embedding_list, text_list])\n",
    "                    # print('Data inserted into the collection.')\n",
    "\n",
    "            count+=1\n",
    "        #         break\n",
    "        # break    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51dbb9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load the instructor model\n",
    "# model= SentenceTransformer('paraphrase-MiniLM-L3-v2')\n",
    "#     # model = INSTRUCTOR(model_name_or_path=\"./ml_models/hkunlp_instructor-xl\")\n",
    "#     print('Model loaded!')\n",
    "\n",
    "# # Process and insert data into Milvus\n",
    "# metadata_list = []\n",
    "# metadata_page_list = []\n",
    "# embedding_list = []\n",
    "# text_list = []\n",
    "# for i in range (len(document_chunks)):\n",
    "#     text = document_chunks[i].page_content\n",
    "#     metadata = f\"{file_name}_{i}\"\n",
    "#     metadata_page = i\n",
    "#     text_list.append(text)\n",
    "#     embeddings = model.encode(text)\n",
    "#     embedding_list.append(embeddings)\n",
    "#     metadata_list.append(metadata)\n",
    "#     metadata_page_list.append(metadata_page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "89f5862b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data inserted into the collection.\n"
     ]
    }
   ],
   "source": [
    "collection.insert([metadata_list, metadata_page_list, embedding_list, text_list])\n",
    "print('Data inserted into the collection.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "603d05a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index created.\n",
      "Collection loaded.\n"
     ]
    }
   ],
   "source": [
    "# Create an index on the \"embeddings\" field\n",
    "index_params = {\n",
    "    'metric_type': 'L2',\n",
    "    'index_type': \"IVF_FLAT\",\n",
    "    'params': {\"nlist\": 2048}\n",
    "}\n",
    "collection.create_index(field_name=\"embeddings\", index_params=index_params)\n",
    "print('Index created.')\n",
    "\n",
    "# Load the collection\n",
    "collection.load()\n",
    "print('Collection loaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "cadb50e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similar documents:\n",
      "Develop cadre training, with anaimoftraining fortransformation, including, inter alia,\n",
      "(a)Mandatory Induction, training forallwith components that develop ethics, citizen\n",
      "centricity andservice delivery excellence besides therule/role-based competencies\n",
      "\n",
      "cadres, competency requirements andtraining trends, sothat there isaclear scheme for\n",
      "development ofafitforpurpose cadre while alsodefining themandatory components. The\n",
      "Cadre training plan shall belinked with thetraining component intheACBPs ofMDOs.11.\n",
      "\n",
      "(a) Strive tohave adiverse mixofregular trainers, trainers ondeputation andexternal\n",
      "trainers, academicians andpractitioners asfaculty members toensure availability\n",
      "ofexperienced faculty;\n",
      "(b) Create robust mechanisms forselection, training, tenure and incentive structure for\n",
      "faculty;\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"What is mandetory part of Cadre training part?\"\n",
    "query_encode = model.encode(query)\n",
    "\n",
    "documents = collection.search(data=[query_encode], anns_field=\"embeddings\", param={\"metric\": \"L2\", \"offset\": 0},\n",
    "                             output_fields=[\"metadata\", \"metadata_page\", \"text\"], limit=3, consistency_level=\"Strong\")\n",
    "\n",
    "print(\"Similar documents:\")\n",
    "for doc in documents:\n",
    "    for i in doc:\n",
    "        print(i.text)\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070a6c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ffe8204",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103ef05f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faaadbdf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c5defa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e681eb97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384\n"
     ]
    }
   ],
   "source": [
    "model= SentenceTransformer('paraphrase-MiniLM-L3-v2')\n",
    "embeddings = model.encode(\"sample text\")\n",
    "print(len(embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ea33a851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Milvus!\n",
      "Collection created!\n"
     ]
    }
   ],
   "source": [
    "MILVUS_HOST = \"localhost\"\n",
    "MILVUS_PORT = \"19530\"\n",
    "\n",
    "connections.connect(host=MILVUS_HOST, port=MILVUS_PORT)\n",
    "print('Connected to Milvus!')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "document_id = FieldSchema(name='document_id', dtype=DataType.INT64, is_primary=True, auto_id=True)\n",
    "metadata = FieldSchema(name='metadata', dtype=DataType.VARCHAR, max_length=50000)\n",
    "metadata_page = FieldSchema(name='metadata_page', dtype=DataType.INT64)\n",
    "# embeddings = FieldSchema(name='embeddings', dtype=DataType.FLOAT_VECTOR, dim=384)\n",
    "embeddings = FieldSchema(name='embeddings', dtype=DataType.FLOAT_VECTOR, dim=384)  \n",
    "\n",
    "text = FieldSchema(name='text', dtype=DataType.VARCHAR, max_length=65535)\n",
    "\n",
    "schema = CollectionSchema(fields=[document_id, metadata, metadata_page, embeddings, text], enable_dynamic_field=True)\n",
    "\n",
    "\n",
    "\n",
    "class SimpleDocument:\n",
    "    def __init__(self, page_content, metadata=None):\n",
    "        self.page_content = page_content\n",
    "        self.metadata = {} if metadata is None else metadata\n",
    "\n",
    "collection_name = 'a2'\n",
    "if not utility.has_collection(collection_name):\n",
    "    coll = Collection(name=collection_name, schema=schema, using='default')\n",
    "    print('Collection created!')\n",
    "else:\n",
    "    coll = Collection(collection_name)\n",
    "    print('Collection already exists.')\n",
    "\n",
    "# Iterate through PDF files in the \"./docs\" directory\n",
    "# document = []\n",
    "# file_name = \"C://Users//Palash Ashok Bhosale//Jupy//Projects//Bot_NLP//pdf//Framework of Roles, Activities and Competencies.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "57dc7471",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 1402, which is longer than the specified 500\n",
      "Created a chunk of size 1033, which is longer than the specified 500\n",
      "Created a chunk of size 694, which is longer than the specified 500\n",
      "Created a chunk of size 1016, which is longer than the specified 500\n",
      "Created a chunk of size 725, which is longer than the specified 500\n",
      "Created a chunk of size 545, which is longer than the specified 500\n",
      "Created a chunk of size 980, which is longer than the specified 500\n",
      "Created a chunk of size 935, which is longer than the specified 500\n",
      "Created a chunk of size 2951, which is longer than the specified 500\n",
      "Created a chunk of size 984, which is longer than the specified 500\n",
      "Created a chunk of size 655, which is longer than the specified 500\n",
      "Created a chunk of size 650, which is longer than the specified 500\n",
      "Created a chunk of size 2013, which is longer than the specified 500\n",
      "Created a chunk of size 1096, which is longer than the specified 500\n",
      "Created a chunk of size 3592, which is longer than the specified 500\n",
      "Created a chunk of size 1224, which is longer than the specified 500\n",
      "Created a chunk of size 1495, which is longer than the specified 500\n",
      "Created a chunk of size 519, which is longer than the specified 500\n",
      "Created a chunk of size 1043, which is longer than the specified 500\n",
      "Created a chunk of size 686, which is longer than the specified 500\n",
      "Created a chunk of size 1068, which is longer than the specified 500\n",
      "Created a chunk of size 614, which is longer than the specified 500\n",
      "Created a chunk of size 759, which is longer than the specified 500\n",
      "Created a chunk of size 676, which is longer than the specified 500\n",
      "Created a chunk of size 620, which is longer than the specified 500\n",
      "Created a chunk of size 674, which is longer than the specified 500\n",
      "Created a chunk of size 1799, which is longer than the specified 500\n",
      "Created a chunk of size 711, which is longer than the specified 500\n",
      "Created a chunk of size 621, which is longer than the specified 500\n",
      "Created a chunk of size 515, which is longer than the specified 500\n",
      "Created a chunk of size 760, which is longer than the specified 500\n",
      "Created a chunk of size 859, which is longer than the specified 500\n",
      "Created a chunk of size 791, which is longer than the specified 500\n",
      "Created a chunk of size 533, which is longer than the specified 500\n",
      "Created a chunk of size 611, which is longer than the specified 500\n",
      "Created a chunk of size 1080, which is longer than the specified 500\n",
      "Created a chunk of size 735, which is longer than the specified 500\n",
      "Created a chunk of size 867, which is longer than the specified 500\n",
      "Created a chunk of size 906, which is longer than the specified 500\n",
      "Created a chunk of size 699, which is longer than the specified 500\n",
      "Created a chunk of size 1125, which is longer than the specified 500\n",
      "Created a chunk of size 1721, which is longer than the specified 500\n",
      "Created a chunk of size 1316, which is longer than the specified 500\n",
      "Created a chunk of size 713, which is longer than the specified 500\n",
      "Created a chunk of size 696, which is longer than the specified 500\n",
      "Created a chunk of size 654, which is longer than the specified 500\n",
      "Created a chunk of size 1047, which is longer than the specified 500\n",
      "Created a chunk of size 602, which is longer than the specified 500\n",
      "Created a chunk of size 647, which is longer than the specified 500\n",
      "Created a chunk of size 730, which is longer than the specified 500\n",
      "Created a chunk of size 519, which is longer than the specified 500\n",
      "Created a chunk of size 1112, which is longer than the specified 500\n",
      "Created a chunk of size 637, which is longer than the specified 500\n",
      "Created a chunk of size 714, which is longer than the specified 500\n",
      "Created a chunk of size 585, which is longer than the specified 500\n",
      "Created a chunk of size 683, which is longer than the specified 500\n",
      "Created a chunk of size 543, which is longer than the specified 500\n",
      "Created a chunk of size 539, which is longer than the specified 500\n",
      "Created a chunk of size 1661, which is longer than the specified 500\n",
      "Created a chunk of size 526, which is longer than the specified 500\n",
      "Created a chunk of size 1692, which is longer than the specified 500\n",
      "Created a chunk of size 1820, which is longer than the specified 500\n",
      "Created a chunk of size 508, which is longer than the specified 500\n",
      "Created a chunk of size 680, which is longer than the specified 500\n",
      "Created a chunk of size 744, which is longer than the specified 500\n",
      "Created a chunk of size 978, which is longer than the specified 500\n",
      "Created a chunk of size 1050, which is longer than the specified 500\n",
      "Created a chunk of size 850, which is longer than the specified 500\n",
      "Created a chunk of size 618, which is longer than the specified 500\n",
      "Created a chunk of size 744, which is longer than the specified 500\n",
      "Created a chunk of size 697, which is longer than the specified 500\n",
      "Created a chunk of size 620, which is longer than the specified 500\n",
      "Created a chunk of size 1741, which is longer than the specified 500\n",
      "Created a chunk of size 1921, which is longer than the specified 500\n",
      "Created a chunk of size 2046, which is longer than the specified 500\n",
      "Created a chunk of size 1737, which is longer than the specified 500\n",
      "Created a chunk of size 624, which is longer than the specified 500\n",
      "Created a chunk of size 1075, which is longer than the specified 500\n",
      "Created a chunk of size 2766, which is longer than the specified 500\n",
      "Created a chunk of size 1042, which is longer than the specified 500\n",
      "Created a chunk of size 1761, which is longer than the specified 500\n",
      "Created a chunk of size 861, which is longer than the specified 500\n",
      "Created a chunk of size 1049, which is longer than the specified 500\n",
      "Created a chunk of size 756, which is longer than the specified 500\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "metadata_list = []\n",
    "metadata_page_list = []\n",
    "embedding_list = []\n",
    "text_list = []\n",
    "\n",
    "folder_path = r\"C:\\Users\\Palash Ashok Bhosale\\Jupy\\Projects\\Bot_NLP\\pdf\"   \n",
    "document = []\n",
    "for file_name in os.listdir(folder_path):\n",
    "    if file_name.endswith(\".pdf\"):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "\n",
    "        with open(file_path, 'rb') as pdf_file:\n",
    "            \n",
    "            pdf_reader = PyPDF2.PdfReader(pdf_file)\n",
    "            count=1\n",
    "            for page in range(0,len(pdf_reader.pages)):\n",
    "                text = pdf_reader.pages[page].extract_text()\n",
    "                \n",
    "                \n",
    "                    \n",
    "                \n",
    "                try:\n",
    "                  document_splitter = CharacterTextSplitter(separator='  \\n \\n', chunk_size=500, chunk_overlap=100)\n",
    "                  document_chunks = document_splitter.split_documents([SimpleDocument(text)])\n",
    "                #   print(document_chunks)\n",
    "\n",
    "\n",
    "\n",
    "                except:\n",
    "                  document_splitter = CharacterTextSplitter(separator='\\n', chunk_size=500, chunk_overlap=100)\n",
    "                  document_chunks = document_splitter.split_documents([SimpleDocument(text)])\n",
    "                #   print(document_chunks)\n",
    "                #   print(\"in except block\")\n",
    "\n",
    "\n",
    "                for i, document_chunk in enumerate(document_chunks):\n",
    "\n",
    "                    document_chunk_text = re.sub(\" \\n\", \" \", document_chunk.page_content)\n",
    "                    paragraph=document_chunk_text\n",
    "                    \n",
    "                    # model = FCoref(device='cuda:0')\n",
    "                    # model = FCoref(device='cpu')\n",
    "                    # preds = model.predict(\n",
    "                    # texts=[paragraph]\n",
    "                    # )\n",
    "\n",
    "                    # preds[0].get_clusters(as_strings=False)\n",
    "                    # clusters=preds[0].get_clusters()\n",
    "\n",
    "\n",
    "                    # for cluster in clusters:\n",
    "                    #     for i in range (len(cluster)):\n",
    "\n",
    "                    #         paragraph=paragraph.replace(cluster[i-1], cluster[0], 1)\n",
    "\n",
    "\n",
    "                    text = paragraph\n",
    "                    metadata = f\"{file_name}_{count}_{i}\"\n",
    "                    metadata_page = i\n",
    "                    text_list.append(text)\n",
    "                    embeddings = model.encode(text)\n",
    "                    embedding_list.append(embeddings)\n",
    "                    metadata_list.append(metadata)\n",
    "                    metadata_page_list.append(metadata_page)\n",
    "                    # print(len(embeddings))\n",
    "                        \n",
    "\n",
    "                \n",
    "\n",
    "                \n",
    "                    \n",
    "\n",
    "                    # collection.insert([metadata_list, metadata_page_list, embedding_list, text_list])\n",
    "                    # print('Data inserted into the collection.')\n",
    "\n",
    "            count+=1\n",
    "        #         break\n",
    "        # break    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc5b7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load the instructor model\n",
    "# model= SentenceTransformer('paraphrase-MiniLM-L3-v2')\n",
    "#     # model = INSTRUCTOR(model_name_or_path=\"./ml_models/hkunlp_instructor-xl\")\n",
    "#     print('Model loaded!')\n",
    "\n",
    "# # Process and insert data into Milvus\n",
    "# metadata_list = []\n",
    "# metadata_page_list = []\n",
    "# embedding_list = []\n",
    "# text_list = []\n",
    "# for i in range (len(document_chunks)):\n",
    "#     text = document_chunks[i].page_content\n",
    "#     metadata = f\"{file_name}_{i}\"\n",
    "#     metadata_page = i\n",
    "#     text_list.append(text)\n",
    "#     embeddings = model.encode(text)\n",
    "#     embedding_list.append(embeddings)\n",
    "#     metadata_list.append(metadata)\n",
    "#     metadata_page_list.append(metadata_page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "779ba58b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data inserted into the collection.\n"
     ]
    }
   ],
   "source": [
    "coll.insert([metadata_list, metadata_page_list, embedding_list, text_list])\n",
    "print('Data inserted into the collection.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "23792a80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index created.\n",
      "Collection loaded.\n"
     ]
    }
   ],
   "source": [
    "# Create an index on the \"embeddings\" field\n",
    "index_params = {\n",
    "    'metric_type': 'L2',\n",
    "    'index_type': \"IVF_FLAT\",\n",
    "    'params': {\"nlist\": 2048}\n",
    "}\n",
    "coll.create_index(field_name=\"embeddings\", index_params=index_params)\n",
    "print('Index created.')\n",
    "\n",
    "# Load the collection\n",
    "coll.load()\n",
    "print('Collection loaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "73e8ff97",
   "metadata": {},
   "outputs": [],
   "source": [
    "### CHARACTER TEXT SPLITTER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e664ab03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similar documents:\n",
      "0\n",
      "iGOT Karmayogi  gives shape to the mandate of the 2012 National Training Policy (NTP) to use e-learning technologies  to cover the training needs of a large number of officials who currently have little or no access to opportunities for quality training. Distance and e-learning provides unparalleled opportunities for meeting the training needs of the large number of civ il servants dispersed across the State in different cities, towns and villages\" (NTP, 2012, p. 32). The NTP also talks of the need to match the competencies of the officer with those required for his/her role  ...essential to match the individual's compe tencies with the jobs they have to do and bridge their competency gaps (p. 2).\n",
      "Framework of Roles, Activities and Competencies.pdf_1_1\n",
      "\n",
      "\n",
      "\n",
      "1\n",
      "When HR managers, especially those who work  as Cadre Controlling Authorities (CCA), need to make decisions regarding officials deployed from the cadre they control to different MDOs, the CP will enable them to figure out which cadre members are better suited to which MDO.\n",
      "Framework of Roles, Activities and Competencies.pdf_1_5\n",
      "\n",
      "\n",
      "\n",
      "2\n",
      "Forallnon-cadre /service specific resources, including temporary hires, etc., there shall be\n",
      "acomponent ofatleastone-week onsite Induction Training tobeanchored byCSTIs which\n",
      "willbespecifically identified forthepurpose. This willbeinaddition tomandatory online\n",
      "Induction modules notified byDOPT ortheMDOs from time totime.V.\n",
      "Develop amandatory immersion programme (know your ministry) forallnew inductees\n",
      "aswell asinstitutionalize programmes which take place regularly throughout theyear for\n",
      "thebenefit ofallemployees.VI.\n",
      "Provide mentoring support intheir training andcapacity building plans tomentor in-\n",
      "service officers.Vll.\n",
      "Collaboration: Develop training collaborations independently orthrough CSTIs\n",
      "preferably onreciprocal basis with global anddomestic partners forboth onsite andonline\n",
      "delivery ofcourses andmodules, sharing oflearning resources andbest practices. These\n",
      "training interventions may beshort-term/long-term, inspecialized domain andfunctional\n",
      "areas, toaddress thecompetencies identified under theACBPs. Such collaborations may\n",
      "also include study tours, team building exercises, exposure visits andtraining onprojects\n",
      "andprogrammes. Nomination ofcivil servants forthese specialized training may bebased\n",
      "onforeseeable Roles andthedesired competencies. Post training utilization plan may also\n",
      "beinbuilt intheselection ofofficers forsuch training.Vlll.\n",
      "Establish Two-way Institutional communication with CSTIs for effective\n",
      "implementation ofcapacity building priorities oftheMinistry/ Department, and obtain\n",
      "feedback from theCSTIs ontheimpact oftraining interventions.IX.\n",
      "Oversee functional performance ofthe CSTIs under their administrative control,\n",
      "including,X.\n",
      "(a) Providing financial support to.CSTIs, linking the same toperformance on\n",
      "accreditation standards. Funds may beprovided fordeveloping state oftheart\n",
      "physical anddigital infrastructure, including forachieving accreditation milestones\n",
      "setunder theCBC guidelines andstandards, through schemes/projects designed for\n",
      "thepurpose.\n",
      "(b) Funding, supervision andmonitoring oftheoperationalization and implementation\n",
      "oftheCSTIs Capacity Building Roadmap.\n",
      "(c) Nurturing theCSTIs asCenters ofExcellence inspecialized/ domain-specific areas\n",
      "inwhich they have aunique standing, byproviding guidance andfunding.\n",
      "9\n",
      "KARMAYOGI GUIDELINES, 2023.pdf_1_0\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"What is mandetory part of Cadre training part?\"\n",
    "query_encode = model.encode(query)\n",
    "\n",
    "documents = coll.search(data=[query_encode], anns_field=\"embeddings\", param={\"metric\": \"L2\", \"offset\": 0},\n",
    "                             output_fields=[\"metadata\", \"metadata_page\", \"text\"], limit=3, consistency_level=\"Strong\")\n",
    "\n",
    "print(\"Similar documents:\")\n",
    "\n",
    "for doc in documents:\n",
    "    num=0\n",
    "    for i in doc:\n",
    "        print(num)\n",
    "        print(i.text)\n",
    "        print(i.metadata)\n",
    "        print(\"\\n\\n\")\n",
    "        \n",
    "        num+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "bce3c615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similar documents:\n",
      "0\n",
      "Step 1 1: Identify levels within each competency and add labels  (Competency Level and Labels )  The competency level is the proficiency level of the competency. These indicate levels of sophistication of the competency described. Competency levels are progressive in nature and normally given in an ascending order. Thus, Level 2 is a more sophisticate d use of that particular competency, when compared to Level 1 and so on. If you are adding the competency in relation to a particular role, you must specify the proficiency level applicable to that role. Also create a label for each individual level (see e xample in Appendix 2).\n",
      "Framework of Roles, Activities and Competencies.pdf_1_4\n",
      "\n",
      "\n",
      "\n",
      "1\n",
      "Step 5: Use the learning objectives to  identify and  describe  competency levels  (Comp etency Level , Labels, and Level Description)   The competency level is the proficiency level of the competency. These indicate levels of sophistication of the competency described , are progressive in nature and normally given in an ascending order . Thus, Level 2 is a more sophisticated use of that particular competency, when compared to Level 1 and so on.\n",
      "Framework of Roles, Activities and Competencies.pdf_1_5\n",
      "\n",
      "\n",
      "\n",
      "2\n",
      "When identifying competency levels and defining each level with descriptors, MDOs must use the five levels and guiding principles as specified in Box 6.   BOX 6. Guiding principles for competency levels\n",
      "Framework of Roles, Activities and Competencies.pdf_1_5\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"Describe each level within each competency Competency Level ?\"\n",
    "query_encode = model.encode(query)\n",
    "\n",
    "documents = coll.search(data=[query_encode], anns_field=\"embeddings\", param={\"metric\": \"L2\", \"offset\": 0},\n",
    "                             output_fields=[\"metadata\", \"metadata_page\", \"text\"], limit=3, consistency_level=\"Strong\")\n",
    "\n",
    "print(\"Similar documents:\")\n",
    "\n",
    "for doc in documents:\n",
    "    num=0\n",
    "    for i in doc:\n",
    "        print(num)\n",
    "        print(i.text)\n",
    "        print(i.metadata)\n",
    "        print(\"\\n\\n\")\n",
    "        \n",
    "        num+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "0d40a4c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similar documents:\n",
      "0\n",
      "As previously mentioned, all six hubs will be accessible to Shanti whether or not her MDO has onboarded onto the platform  (see Figure 3 for Shantis journey through the iGOT Karmayogi platform) . These unique features imply that  the iGOT learning hub  will need to have:\n",
      "Framework of Roles, Activities and Competencies.pdf_1_1\n",
      "\n",
      "\n",
      "\n",
      "1\n",
      "Asdistinct from class room orbrick andmortar training, thecapacity building efforts of\n",
      "using e-learning resources [exclusively orpartially (phygital)] through iGoT Karmayogi\n",
      "platform follow amore democratic approach, agnostic tohierarchies orservices and aim to\n",
      "build strong knowledge base ofemployees inworkplace related operations. iGOT\n",
      "Karmayogi platform hasbeen conceived andbuilt asasolution space;\n",
      "a)Toprovide forsystems thatcontinually tapondemand forcompetencies identified by\n",
      "MDOs intheir ACBPs toidentify requirements oflearning resources;\n",
      "b)Tocreate mechanisms forassessment ofcompetencies possessed byindividual\n",
      "employees; and\n",
      "c)Toensure availability ofquality content, intheform ofonline courses andmodules, for\n",
      "filling thegapinrequired competencies.\n",
      "Thecompetencies canbeacquired asmandated or,alternatively, according totheinterest\n",
      "and inclination ofindividual employees. With online assessments, iGOT Karmayogi\n",
      "platform will also provide anagile system ofreal time assessed capacities within\n",
      "Government ecosystem. This canbematched wherever requirement ofsuch competencies\n",
      "israised byMDOs atanytime orthrough their ACBPs. Atthesame time, thedevelopment\n",
      "ofcapacity ofCSTIs tobeabletoserve asanimportant player intraining ofCivil Servants\n",
      "would continue tobeguided andsupported bytheadministrative Ministries, DoPT aswell\n",
      "asCBC inanintegrated framework.\n",
      "1.7 These guidelines, inter-alia, align totwocomponents:\n",
      "a)Accreditation Framework forCSTIs; and\n",
      "b)Integration with competency-based systems ofiGOT Karmayogi platform.\n",
      "They aimtodrive aunified system ofdelivery andassessment ofindividual capacities for\n",
      "career progression asalso systemic enhancement foroverall achievement ofMission\n",
      "Outcomes. Itisenvisaged thattheinstitutional training interventions incomplementarity\n",
      "with online capacity building interventions oniGOT Karmayogi platform would facilitate\n",
      "theoverall objective ofshift from rule-based system toarole-based Human Resource\n",
      "Management inGovernment.\n",
      "TheNational Training approach, therefore, hastoharmoniously blend andrealign therole\n",
      "ofvarious CSTIs soastofully complement theefforts ofother pillars ofMission Karmayogi.\n",
      "Itisalsoacknowledged thatthere isalarge pool ofresources inMDOs, which isnotpartof\n",
      "anyorganized civil services. Asthetraining andcapacity building ofthese resources will\n",
      "directly orindirectly contribute totheperformance oftheorganization, therefore, there isa\n",
      "need toinclude this resource pool inthefold oftheTraining and Capacity Building\n",
      "framework.1.6\n",
      "1.8\n",
      "1.9These guidelines arebeing framed inconsultation with CBC, SPY, andafter factoring in\n",
      "thesuggestions and recommendations ofMDOs, CSTIs, States and their CSTIs, shared\n",
      "during theNational Training Conclave 2023. These guidelines shall steer the efforts ofall\n",
      "3\n",
      "KARMAYOGI GUIDELINES, 2023.pdf_1_0\n",
      "\n",
      "\n",
      "\n",
      "2\n",
      "A combination of all these user scores, alongside others,  will be used to build an organisation score on the PMs dashboard  and subsequently in the annual SCSR (see Table 3  for more information on this ).  Buyers on the iGOT Karmayogi  learning hub  will fall into one of the following categories:\n",
      "Framework of Roles, Activities and Competencies.pdf_1_2\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"What is learn hub?\"\n",
    "query_encode = model.encode(query)\n",
    "\n",
    "documents = coll.search(data=[query_encode], anns_field=\"embeddings\", param={\"metric\": \"L2\", \"offset\": 0},\n",
    "                             output_fields=[\"metadata\", \"metadata_page\", \"text\"], limit=3, consistency_level=\"Strong\")\n",
    "\n",
    "print(\"Similar documents:\")\n",
    "\n",
    "for doc in documents:\n",
    "    num=0\n",
    "    for i in doc:\n",
    "        print(num)\n",
    "        print(i.text)\n",
    "        print(i.metadata)\n",
    "        print(\"\\n\\n\")\n",
    "        \n",
    "        num+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "7825f5f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similar documents:\n",
      "0\n",
      "iGOT 2.0  An\tInitiative\tfor\tCapacity\tDevelopment\tof\tCivil\tServices\t|\tConsultation\tPaper\ton\tApproach\tto\tStrategy\tand\tImplementation  | 41 With the implementation of iGOT 2.0 already underway, there are some key choices which have been made\n",
      "Digital\tplatform\n",
      "The digital platform is core to iGOT 2.0 and will drive all  interactions on it. The platform needs to be scalable to serve more than 2 crore officials, configurable to enable introduction of  features incrementally, well proven for purposes of capacity  development and secure. The choice of the underlying  technology therefore becomes of essence. iGOT 2.0 is  implemented on DIKSHA, an open source learning solution, made in India and made for India. DIKSHA as a learning platform has been proven with scale and configurability, the same core is being repurposed to develop iGOT 2.0. FRACs\tto\tdrive\tthe\tplatform\ttaxonomy\n",
      "iGOT 2.0 will be built on taxonomy that is aligned to FRACs to ensure a fit for use for the future workforce in government. FRACs will evolve over time as competencies evolve, and iGOT 2.0 will have to evolve accordingly. FRACs brings in a formal yet loosely coupled structure (roles, activities, competencies including skills are configurable and not tightly linked) in defining the  competencies that is easily replicable across departments. The intercoupling of evolving FRACs and the configurable taxonomy graph of the platform is a key driver for the evolvability of the platform is a key driver for the evolvability of iGOT 2.0.\n",
      "A\tphased\tapproach\tof\tiGOT\t2.0\t  implementation\tand\trollout\n",
      "A choice has been made to implement iGOT 2.0 in a phased  manner with features being introduced incrementally with Appendix\t2\t \tKey\tConsiderations\tfor\t  Choices\tMade\n",
      "Indian Technology for an Indian Platform solving an Indian Problem\n",
      "Design for Future,  Implement for Now\n",
      "iGOT Blue Book Final.pdf_1_0\n",
      "\n",
      "\n",
      "\n",
      "1\n",
      "iGOT 2.0  An\tInitiative\tfor\tCapacity\tDevelopment\tof\tCivil\tServices\t|\tConsultation\tPaper\ton\tApproach\tto\tStrategy\tand\tImplementation  | 37 Designed for the future, iGOT 2.0 will be a self-sustaining platform, managed by DoPT with departments, CTIs and States co-creating assets on the platform and contributing to its uptake. A  transformative initiative of this size requires commitment and acceptance from all stakeholders to be successful, with each stakeholder group having a specific role to play. Given the sheer volume of potential users, rollout of the platform to the department and states will be performed in a phased  manner. The pilot launch has been envisaged which will enable early validation of the features and effectiveness of the platform, before being rolled out to the departments and states. DoPT will engage with the departments and states to formalize an  onboarding arrangement. This will include bringing in necessary policy interventions whenever needed, guiding the departments and states on the key roles and activities that they need to play and handholding them through the onboarding journey, creating toolkits and standard operating procedures, and training the  relevant officials to enhance the readiness. Over time, the  responsibilities will shift to the departments and states, and they will need to start creating internal capacity to deliver to their responsibilities.\n",
      "As the backbone for the larger bureaucratic reform, iGOT 2.0 will lay the foundation for multiple transformative changes in  learning and capacity building in the government. It will  continuously augment and enhance capacities while driving social good and innovation across the ecosystem. As we move towards a digital and open society, it is this endeavour of making capacity building of officials a national mission- that will ultimately  empower the Indian government and enable it to deliver to  rapidly shifting aspirations. Conclusion\t\n",
      "In this land of the Ganga, there was an education of culture. But, more importantly, there was a culture of education.   PM Shri Narendra Modi\n",
      "iGOT Blue Book Final.pdf_1_0\n",
      "\n",
      "\n",
      "\n",
      "2\n",
      "iGOT 2.0  An\tInitiative\tfor\tCapacity\tDevelopment\tof\tCivil\tServices\t|\tConsultation\tPaper\ton\tApproach\tto\tStrategy\tand\tImplementation  | 33 The adoption of iGOT 2.0 will rely on a centrally curated learning platform but with decentralized execution. Each stakeholder will require a clear understanding of what is required from it for the roll out. Role\tof\tDoPT\n",
      " DoPT will enable the implementation and rollout of iGOT 2.0. It will fund and manage the development and  enhancement of the platform over a period by incrementally bringing in new features based on inputs from the  stakeholders till the time the platform becomes  self-sustaining. The same can be leveraged by CCAs and all government training institutions as a central resource,  thereby further enabling cross-sharing of content and  leading practices.    DoPT will develop a Learning Architecture which provides the governance framework for entire learning reforms  agenda, including iGOT 2.0.\n",
      " DoPT will develop policies necessary to enable iGOT 2.0 and other capacity building initiatives in government. DoPT will, as per requirements, create suitable and competent sub-committees to bring in expert opinions on critical policy decisions.\n",
      " DoPT will conduct annual Public HR Summit, as an emit to the world on the advancements and thought leadership that India brings on reforming HR management and capacity building in public sector. DoPT will publish the annual State of Civil Services Report capturing the performance of each Central Department, organizations and State on several parameters including the effort and spend made by the departments around capacity building of Civil Service.\n",
      " DoPT will develop and maintain the PMs iGOT 2.0  dashboard capturing the critical Key Performance Indicators (KPIs) around capacity building of officials , at departmental and state levels. Roles\tand\tResponsibilities\tof\tKey\tStakeholders\n",
      "iGOT Blue Book Final.pdf_1_0\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"What DOES CORE OF IGOT BOUND TO?\"\n",
    "query_encode = model.encode(query)\n",
    "\n",
    "documents = coll.search(data=[query_encode], anns_field=\"embeddings\", param={\"metric\": \"L2\", \"offset\": 0},\n",
    "                             output_fields=[\"metadata\", \"metadata_page\", \"text\"], limit=3, consistency_level=\"Strong\")\n",
    "\n",
    "print(\"Similar documents:\")\n",
    "\n",
    "for doc in documents:\n",
    "    num=0\n",
    "    for i in doc:\n",
    "        print(num)\n",
    "        print(i.text)\n",
    "        print(i.metadata)\n",
    "        print(\"\\n\\n\")\n",
    "        \n",
    "        num+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b53dc598",
   "metadata": {},
   "outputs": [],
   "source": [
    "### RECURSIVE CHARACTER TEXT SPLITTER "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "776070e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similar documents:\n",
      "0\n",
      "Develop cadre training, with anaimoftraining fortransformation, including, inter alia,\n",
      "(a)Mandatory Induction, training forallwith components that develop ethics, citizen\n",
      "centricity andservice delivery excellence besides therule/role-based competencies\n",
      "KARMAYOGI GUIDELINES, 2023.pdf_1_5\n",
      "\n",
      "\n",
      "\n",
      "1\n",
      "cadres, competency requirements andtraining trends, sothat there isaclear scheme for\n",
      "development ofafitforpurpose cadre while alsodefining themandatory components. The\n",
      "Cadre training plan shall belinked with thetraining component intheACBPs ofMDOs.11.\n",
      "KARMAYOGI GUIDELINES, 2023.pdf_1_4\n",
      "\n",
      "\n",
      "\n",
      "2\n",
      "(a) Strive tohave adiverse mixofregular trainers, trainers ondeputation andexternal\n",
      "trainers, academicians andpractitioners asfaculty members toensure availability\n",
      "ofexperienced faculty;\n",
      "(b) Create robust mechanisms forselection, training, tenure and incentive structure for\n",
      "faculty;\n",
      "KARMAYOGI GUIDELINES, 2023.pdf_1_4\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"What is mandetory part of Cadre training part?\"\n",
    "query_encode = model.encode(query)\n",
    "\n",
    "documents = collection.search(data=[query_encode], anns_field=\"embeddings\", param={\"metric\": \"L2\", \"offset\": 0},\n",
    "                             output_fields=[\"metadata\", \"metadata_page\", \"text\"], limit=3, consistency_level=\"Strong\")\n",
    "\n",
    "print(\"Similar documents:\")\n",
    "\n",
    "for doc in documents:\n",
    "    num=0\n",
    "    for i in doc:\n",
    "        print(num)\n",
    "        print(i.text)\n",
    "        print(i.metadata)\n",
    "        print(\"\\n\\n\")\n",
    "        \n",
    "        num+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "d1037684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similar documents:\n",
      "0\n",
      "Labels)12. Describe each level within each competency\n",
      "(Competency Level Description)\n",
      "Framework of Roles, Activities and Competencies.pdf_1_10\n",
      "\n",
      "\n",
      "\n",
      "1\n",
      "Description)  The competency level is the proficiency level of the competency. These indicate levels of sophistication of the competency described. The level description is an observable description of each proficiency level of a given\n",
      "Framework of Roles, Activities and Competencies.pdf_1_9\n",
      "\n",
      "\n",
      "\n",
      "2\n",
      "Description)   The competency level is the proficiency level of the competency. These indicate levels of sophistication of the competency described , are progressive in nature and normally given in an ascending order . Thus, Level 2 is a more sophisticated use of that particular\n",
      "Framework of Roles, Activities and Competencies.pdf_1_9\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"Describe each level within each competency Competency Level ?\"\n",
    "query_encode = model.encode(query)\n",
    "\n",
    "documents = collection.search(data=[query_encode], anns_field=\"embeddings\", param={\"metric\": \"L2\", \"offset\": 0},\n",
    "                             output_fields=[\"metadata\", \"metadata_page\", \"text\"], limit=3, consistency_level=\"Strong\")\n",
    "\n",
    "print(\"Similar documents:\")\n",
    "\n",
    "for doc in documents:\n",
    "    num=0\n",
    "    for i in doc:\n",
    "        print(num)\n",
    "        print(i.text)\n",
    "        print(i.metadata)\n",
    "        print(\"\\n\\n\")\n",
    "        \n",
    "        num+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "999ab665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similar documents:\n",
      "0\n",
      "imply that  the iGOT learning hub  will need to have:\n",
      "Framework of Roles, Activities and Competencies.pdf_1_14\n",
      "\n",
      "\n",
      "\n",
      "1\n",
      "2. Learning hub:  facilitating competency building through suitable courses, assessments and learning recommendations  (i.e. CBPs) . 3. Career hub:  enabling the government to solve the complex problem of encouraging lifelong learning, and finding the right person for the right job.\n",
      "Framework of Roles, Activities and Competencies.pdf_1_12\n",
      "\n",
      "\n",
      "\n",
      "2\n",
      "the iGOT learning hub  to close the competency gaps among them  in a timely and eff icient manner. The learning hub  will have to have unique features in order to do so. Given the pace of change in the way work is organised, often due to technological advancements, it is\n",
      "Framework of Roles, Activities and Competencies.pdf_1_6\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"What is learn hub?\"\n",
    "query_encode = model.encode(query)\n",
    "\n",
    "documents = collection.search(data=[query_encode], anns_field=\"embeddings\", param={\"metric\": \"L2\", \"offset\": 0},\n",
    "                             output_fields=[\"metadata\", \"metadata_page\", \"text\"], limit=3, consistency_level=\"Strong\")\n",
    "\n",
    "print(\"Similar documents:\")\n",
    "\n",
    "for doc in documents:\n",
    "    num=0\n",
    "    for i in doc:\n",
    "        print(num)\n",
    "        print(i.text)\n",
    "        print(i.metadata)\n",
    "        print(\"\\n\\n\")\n",
    "        \n",
    "        num+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "db98e84b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similar documents:\n",
      "0\n",
      "designed keeping the civil service learner at the core. The key guiding principles which the iGOT 2.0 platform will adhere to are as follows:  iGOT 2.0 will be the common learning platform across all ministries, departments, states and organisations and will\n",
      "iGOT Blue Book Final.pdf_1_3\n",
      "\n",
      "\n",
      "\n",
      "1\n",
      "The digital platform is core to iGOT 2.0 and will drive all  interactions on it. The platform needs to be scalable to serve more than 2 crore officials, configurable to enable introduction of  features incrementally, well proven for purposes of capacity\n",
      "iGOT Blue Book Final.pdf_1_1\n",
      "\n",
      "\n",
      "\n",
      "2\n",
      "iGOT 2.0 is built on a multi-layered architecture with decoupled modules which support all interactions and emits data continu -\n",
      "ously and in real time. The core modules of the platform and the key design principles have been captured in the following figure.\n",
      "iGOT Blue Book Final.pdf_1_5\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"What DOES CORE OF IGOT BOUND TO?\"\n",
    "query_encode = model.encode(query)\n",
    "\n",
    "documents = collection.search(data=[query_encode], anns_field=\"embeddings\", param={\"metric\": \"L2\", \"offset\": 0},\n",
    "                             output_fields=[\"metadata\", \"metadata_page\", \"text\"], limit=3, consistency_level=\"Strong\")\n",
    "\n",
    "print(\"Similar documents:\")\n",
    "\n",
    "for doc in documents:\n",
    "    num=0\n",
    "    for i in doc:\n",
    "        print(num)\n",
    "        print(i.text)\n",
    "        print(i.metadata)\n",
    "        print(\"\\n\\n\")\n",
    "        \n",
    "        num+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad17684",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
